{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn-lab6-v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fathimath-Rifna-VK/fmml2021/blob/main/Module_11_cnn_Lab_6_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQqIVNVYnA90"
      },
      "source": [
        "# Convolutional Neural Networks - Lab 6\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        " <td>\n",
        " <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1ONT6aEygsYgEyQjgx5Sblxds_KsN6_4T?usp=sharing\"><img height=\"32px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" />Run in Google Colab</a>\n",
        " </td>\n",
        " <td>\n",
        " <a target=\"_blank\" href=\"https://github.com/Foundations-in-Modern-Machine-Learning/course-contents/blob/main/CNN/cnn_lab6.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        " </td>\n",
        "</table>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "Module Coordinator: Ekta Gavas\n",
        "\n",
        "Email: ekta.gavas@research.iiit.ac.in\n",
        "\n",
        "## Description\n",
        "---\n",
        "This lab is intended to provide a brief introduction to convolutional autoencoders. We will study image denoising application by adding noise to images and reconstruct the cleaner versions.\n",
        "\n",
        "## Starter Code\n",
        "---\n",
        "To make your task easier, we provide you the starter code to perform the lab exercises. It is expected that you should try to understand what the code does and analyze the output. We will be using Pytorch framework for the implementation of this lab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svya7__kbYdR"
      },
      "source": [
        "## Convolutional AutoEncoders\n",
        "In previous modules, you have studied autoencoders (AE) for dimensionality reduction. To recall, autoencoders consists of an encoder network, which takes the input data and encodes it to fit into the latent space. These networks are trained in an unsupervised way to attempt to copy inputs to output. Because neural networks are capable of learning nonlinear relationships, this can be thought of as a more powerful (nonlinear) generalization of PCA. Whereas PCA attempts to discover a lower dimensional hyperplane which describes the original data, autoencoders are capable of learning nonlinear manifolds (a manifold is defined in simple terms as a continuous, non-intersecting surface). The difference between these two approaches is visualized below.\n",
        "\n",
        "<img src='https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-07-at-8.52.21-AM.png' height=370/>\n",
        "\n",
        "Convolutional layers can be incorporated in the encoder and decoders to learn important features from the image data (3D vectors) instead of flattened vectors (linear AE). The input image is downsampled to give a latent representation of smaller dimensions and force the autoencoder to learn a compressed version of the images. Then, it is upsampled back to reconstruct the input. Convolutional AE can be used for noise reduction where it learns to reconstruct a cleaner version of the image. The reconstructed image is compared to the original (without noise) image to compute the reconstruction loss. This way, the AE learns more robust features from image data.\n",
        "\n",
        "<img src='https://lilianweng.github.io/lil-log/assets/images/denoising-autoencoder-architecture.png' height=400px width=900px/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MYQ--7lK68y"
      },
      "source": [
        "### Noise reduction using Convolutional Autoencoder\n",
        "We will perform noise reduction similar to above figure on Fashion-MNIST dataset from Pytorch. We will add noise to the images for the network input and take targets as the original images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8QwSJ5obIHr"
      },
      "source": [
        "# Import packages\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7bIS3wM568K"
      },
      "source": [
        "# Device configuration (whether to run on GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS2tiera6Dfk"
      },
      "source": [
        "# Set seeds for reproducibility\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ0n6wa47uZu"
      },
      "source": [
        "#### Load Fashion-MNIST data\n",
        "We will use the [Fashion-MNIST dataset](https://pytorch.org/vision/stable/datasets.html#fashion-mnist) from torchvision Pytorch and setup the train and test dataloaders in an usual manner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr2uSnxn7nIb"
      },
      "source": [
        "batch_size_train = 128\n",
        "batch_size_test = 128\n",
        "\n",
        "# Images in torchvision datasets are PIL Images in range [0,1] so we need\n",
        "# 'ToTensor' transform to convert them into tensors\n",
        "train_data = torchvision.datasets.FashionMNIST('./data', train=True, download=True,\n",
        "                             transform=torchvision.transforms.ToTensor())\n",
        "test_data = torchvision.datasets.FashionMNIST('./data', train=False, download=True,\n",
        "                             transform=torchvision.transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size_train, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size_test, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43ZzTl-078NJ"
      },
      "source": [
        "# Helper function to plot data\n",
        "def plot_data(images, labels, classes=None):\n",
        "  figure = plt.figure(figsize=(9, 4))\n",
        "  cols, rows = 5, 2\n",
        "  sample_idx = 0\n",
        "  for i in range(1, cols * rows + 1):\n",
        "      img, label = images[sample_idx], labels[sample_idx]\n",
        "      sample_idx += 1\n",
        "      figure.add_subplot(rows, cols, i)\n",
        "      if classes is not None:\n",
        "        label = classes[label]\n",
        "      plt.title('Label:' +str(label))\n",
        "      plt.axis(\"off\")\n",
        "      plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "      \n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1bnP8EyqktD"
      },
      "source": [
        "for i, sample in enumerate(train_loader):\n",
        "  images, labels = sample\n",
        "  plot_data(images, train_data.targets.numpy())\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYYNFnPk8LWD"
      },
      "source": [
        "#### Define the Autoencoder model\n",
        "We stack up all our layers to perform encoding first with ReLU activation function. We also have the pooling layer after each convolutional layer. We thus obtain the latent space representation. Further, the decoding of the latent space representation takes place. Again all the ConvTranspose2d() go through the ReLU activation function. [ConvTranspose2d()](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html) implements the reverse operation of Conv2d layer i.e reverse of convolution operation. The final decoding layer is coupled with the sigmoid activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-e1DrVT8GYt"
      },
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # Encoder\n",
        "        self.enc1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
        "        self.enc2 = nn.Conv2d(64, 32, kernel_size=3, padding=1)\n",
        "        self.enc3 = nn.Conv2d(32, 16, kernel_size=3, padding=1)\n",
        "        self.enc4 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # Decoder\n",
        "        self.dec1 = nn.ConvTranspose2d(8, 8, kernel_size=3, stride=2)  \n",
        "        self.dec2 = nn.ConvTranspose2d(8, 16, kernel_size=3, stride=2)\n",
        "        self.dec3 = nn.ConvTranspose2d(16, 32, kernel_size=2, stride=2)\n",
        "        self.dec4 = nn.ConvTranspose2d(32, 64, kernel_size=2, stride=2)\n",
        "        \n",
        "        self.out = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encode\n",
        "        x = F.relu(self.enc1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.enc2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.enc3(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.enc4(x))\n",
        "        x = self.pool(x) # the latent space representation\n",
        "        \n",
        "        # decode\n",
        "        x = F.relu(self.dec1(x))\n",
        "        x = F.relu(self.dec2(x))\n",
        "        x = F.relu(self.dec3(x))\n",
        "        x = F.relu(self.dec4(x))\n",
        "        x = torch.sigmoid(self.out(x))\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9pAMB0C6JBG"
      },
      "source": [
        "# Build the model object and put on the device\n",
        "model = Autoencoder().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux_2PGgT8diG"
      },
      "source": [
        "#### Define Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZDAwCNb8VER"
      },
      "source": [
        "# Reconstuction loss (to compare original and reconstructed image)\n",
        "loss_func = nn.MSELoss() # mean squared error loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fwSTPmI8lQP"
      },
      "source": [
        "#### Define optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GieENlOa8heQ"
      },
      "source": [
        "# Basic SGD optimizer with 0.01 learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svJ3-UB187qa"
      },
      "source": [
        "#### Train the model\n",
        "Function to add Gaussian noise to the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjcVijtnCOqd"
      },
      "source": [
        "def add_noise(image, mean=0., std=0.2):\n",
        "  return image + torch.randn(image.size()) * std + mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t94F0wxMefKz"
      },
      "source": [
        "Helper function for training/testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDXNReyi8n5o"
      },
      "source": [
        "def train(num_epochs, model, train_loader, loss_func, optimizer):\n",
        "\n",
        "  # Training mode\n",
        "  model.train()\n",
        "\n",
        "  train_losses = []\n",
        "  train_acc = []\n",
        "\n",
        "  # Train the model\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    running_acc = 0\n",
        "    for i, (images, _) in enumerate(train_loader):\n",
        "      \n",
        "      # clear gradients for this training step   \n",
        "      optimizer.zero_grad()    \n",
        "\n",
        "      # Add noise to image\n",
        "      noisy_images = add_noise(images)\n",
        "\n",
        "\n",
        "      # Put data on devices\n",
        "      images = images.to(device)\n",
        "      noisy_images = noisy_images.to(device)\n",
        "\n",
        "      # Forward pass with noisy data\n",
        "      output = model(noisy_images)\n",
        "\n",
        "      # Calculate loss with reconstructed images and original images\n",
        "      loss = loss_func(output, images)\n",
        "\n",
        "      # Backpropagation, compute gradients \n",
        "      loss.backward()\n",
        "\n",
        "      # Apply gradients             \n",
        "      optimizer.step()                \n",
        "      \n",
        "      # Running loss\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    train_losses.append(epoch_loss)\n",
        "    print ('Epoch {}/{}, Loss: {:.4f}'.format(epoch + 1, num_epochs, epoch_loss))\n",
        "\n",
        "  return train_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFYI98OtNjCc"
      },
      "source": [
        "def test(model, test_loader):\n",
        "  # Eval mode\n",
        "  model.eval()\n",
        "  test_acc = 0\n",
        "  correct = 0\n",
        "  add_noise = AddGaussianNoise()\n",
        "  for i, (images, labels) in enumerate(test_loader):\n",
        "    # Deactivate autograd engine (don't compute grads since we're not training)\n",
        "    with torch.no_grad():\n",
        "      # Add noise to image\n",
        "      noisy_images = add_noise(images)\n",
        "      # Put data on devices\n",
        "      images = images.to(device)\n",
        "      noisy_images = noisy_images.to(device)\n",
        "\n",
        "      # Forward pass\n",
        "      output = model(noisy_images)\n",
        "    break\n",
        "\n",
        "  # Plot the noisy and corresponding reconstructed images\n",
        "  plot_data(noisy_images.data.cpu().numpy(), labels.numpy(), test_loader.dataset.classes)\n",
        "  plot_data(images.data.cpu().numpy(), labels.numpy(), test_loader.dataset.classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6pYjXgchc3E"
      },
      "source": [
        "Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax9XMoe5H_ik"
      },
      "source": [
        "num_epochs = 5  # iterations\n",
        "train_losses = train(num_epochs, model, train_loader, loss_func, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L6zRBlfByjr"
      },
      "source": [
        "plt.plot(np.arange(1,len(train_losses)+1),train_losses)\n",
        "plt.xlabel('Training Loss')\n",
        "plt.ylabel('Epochs')\n",
        "plt.title('Loss vs Epochs')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYW-_wTfWvYl"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rReuhwjpXr5K"
      },
      "source": [
        "# Evaluate the model on testing data and plot predictions\n",
        "test(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-VWB2K7RnOK"
      },
      "source": [
        "As you can observe, the network learns to remove noise from the images and produce a cleaner version. Now, the encoder of the network which has already learnt important features from the dataset can be further used to perform classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oniT6gixQZ7_"
      },
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EnJZ3_SYiYc"
      },
      "source": [
        "Q 1: If you recall, in the first lab exercise, you calculated the shape of output map when a 500 x 500 image is convolved with a 5 x 5 kernel, padding 3 and stride 2. Let's say we apply ConvTranspose2d on this output map. Can you calculate the size of the resultant image? Do you think the size would be same as original image (500 x 500)?\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5XatV34Qia0"
      },
      "source": [
        "Q 2: List a few practical applications of convolutional autoencoders.\n",
        "\n",
        "Answer:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV2vN3x7Srq8"
      },
      "source": [
        "Q 3: The loss function we chose here was Mean Squared Error loss. Which loss function would you choose if the input data was binary?\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqMzkKLBq18x"
      },
      "source": [
        "Q 4: What change do we need to make for the autoencoder to reduce into PCA?\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuLCRhK3sBFH"
      },
      "source": [
        "Q 5: We want to perform clustering on MNIST data. What advantage we can get if we use bottleneck layer features of a CNN autoencoder for clustering instead of raw images?\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0Rm8FB-Qn4K"
      },
      "source": [
        "## References and Additional Resources:\n",
        "\n",
        "*   [Autoencoder Neural Network: Application to Image Denoising](https://debuggercafe.com/autoencoder-neural-network-application-to-image-denoising/)\n",
        "*   [Deep inside: Autoencoders - Medium Article](https://towardsdatascience.com/deep-inside-autoencoders-7e41f319999f)\n",
        "*   [Denoising autoencoder for CIFAR10](https://codahead.com/blog/a-denoising-autoencoder-for-cifar-datasets)\n",
        "*   [Autoencoders: Overview of Research and Applications](https://towardsdatascience.com/autoencoders-overview-of-research-and-applications-86135f7c0d35)\n",
        "*   [AutoEncoders](https://www.jeremyjordan.me/autoencoders/)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzT-8aOSDhYt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
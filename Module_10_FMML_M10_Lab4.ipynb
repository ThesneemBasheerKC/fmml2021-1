{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FMML:M10:Lab4",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fathimath-Rifna-VK/fmml2021/blob/main/Module_10_FMML_M10_Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReGpBDTRz_ZY"
      },
      "source": [
        "# Working with large datasets\n",
        "\n",
        "Till now, we have mostly used small datasets that fully fit within the memory. This will not always be possible. There are a lot of HUGE datasets (multiple terabytes), so we need to learn how to use them.\n",
        "\n",
        "Technically, you can work with datasets that don't reside on the disk at all! Every dataset example is fetched over the network as and when needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flkx2KHC3c5X"
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, transform\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from tqdm.auto import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm2MWN1kz7-D"
      },
      "source": [
        "# download the example dataset\n",
        "!rm -r data cifar10.zip\n",
        "!mkdir data\n",
        "# slightly modified version of https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "!wget https://web.iiit.ac.in/~yoogottam.khandelwal/cifar10.zip\n",
        "!unzip cifar10.zip -d data | tail"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-3MNk-pG3cS"
      },
      "source": [
        "## Analyzing the data\n",
        "\n",
        "We see that the labels are strings and not integers (which we would prefer for a class).\n",
        "We'll need to use a label encoder to convert string labels into numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL6bIYIuFFyf"
      },
      "source": [
        "pd.read_csv(\"data/data.csv\").head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjgtuGQF2DCY"
      },
      "source": [
        "# Writing custom datasets\n",
        "\n",
        "pytorch provides a great interface for implementing custom datasets: `torch.utils.data.Dataset`. This is an abstract class representing an actual dataset.\n",
        "\n",
        "To see how we can implement one, we'll be using the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        "\n",
        "In this zip file, we have:\n",
        " - A CSV file containing image names and the class (one of 10 classes)\n",
        " - images\n",
        "\n",
        "Clearly, we need to do some form of processing before using this directly for training a model. We'll be going through that now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "505jDC6c8E2v"
      },
      "source": [
        "## `Dataset` class\n",
        "\n",
        "For writing a dataset, we need to create a class which inherits `Dataset`. We need to implement 2 methods:\n",
        " - `__len__`: This should return the length of our dataset\n",
        " - `__getitem__(i)`: This should return the `i`th item in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLgYJLHB8fHT"
      },
      "source": [
        "class CIFAR10Dataset(Dataset):\n",
        "    def __init__(self, root_dir=\"./data\", transforms=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir   (string)  : Directory with all the images and the csv file\n",
        "            transforms (Callable): image goes through these transforms\n",
        "        \"\"\"\n",
        "        # use pandas to read the csv\n",
        "        # we are only using 1/10th of the full data because CIFAR10 is HUGE\n",
        "        # otherwise, we wouldn't be able to train this\n",
        "        self.data = pd.read_csv(f\"{root_dir}/data.csv\").sample(frac=0.1, random_state=42)\n",
        "        # this is where the images are stored\n",
        "        self.root_dir = root_dir\n",
        "\n",
        "        # label encoder\n",
        "        label_encoder = LabelEncoder()\n",
        "        self.data[\"label_numeric\"] = label_encoder.fit_transform(self.data[\"label\"])\n",
        "\n",
        "        # transformations to the dataset\n",
        "        # we'll come to this soon\n",
        "        if transforms is None:\n",
        "            # an identity function, returns it's argument\n",
        "            transforms = lambda x: x\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        This should return the number of items in the dataset\n",
        "        \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        This should return the item at index `idx` from the dataset\n",
        "        \"\"\"\n",
        "        data = self.data.iloc[idx]\n",
        "        img_name = os.path.join(self.root_dir, data[\"image_path\"])\n",
        "        # read the image\n",
        "        image = io.imread(img_name)\n",
        "        label = data[\"label\"]\n",
        "        label_numeric = data[\"label_numeric\"]\n",
        "\n",
        "        # send the image through the provided transformations\n",
        "        image = self.transforms(image)\n",
        "        return image, label_numeric, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HGk1RJl-St2"
      },
      "source": [
        "cfds = CIFAR10Dataset()\n",
        "print(f\"Number of data items: {len(cfds)}\")\n",
        "\n",
        "print(cfds[0][1:])\n",
        "plt.imshow(cfds[0][0][:,:,::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ppt1T2fCTGfd"
      },
      "source": [
        "# Writing custom transforms\n",
        "\n",
        "Most of the times, we need to process the data before sending it to the model. There are a lot of reasons to do this including:\n",
        " - resizing the image\n",
        " - data augmentation (flipping, rotation, crops, etc)\n",
        " - converting data to the correct format (`np` array to `torch` tensor)\n",
        "\n",
        "For this example, we'll horizontally flip the images for augmentation and convert the data to a tensor before training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZL48D5wT9TL"
      },
      "source": [
        "We don't need to inherit from a special class to create a transform.\n",
        "A transform is basically a function that takes in a data sample and returns it.\n",
        "\n",
        "That is also the restriction: It can only take a single argument (i.e. the data sample).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfqDZ6V-Ty0m"
      },
      "source": [
        "# example of a transform that doesn't need any parameters\n",
        "# Convert ndarrays in sample to Tensors\n",
        "\n",
        "# normal function\n",
        "def to_tensor(image):\n",
        "    image = image.copy().astype(\"float32\")\n",
        "    # swap color axis because\n",
        "    # numpy image: H x W x C\n",
        "    # torch image: C x H x W\n",
        "    # also, shift the image to 0-1 instead of 0-255\n",
        "    image = image.transpose((2, 0, 1)) / 255\n",
        "    return torch.from_numpy(image)\n",
        "\n",
        "# example\n",
        "print(\"to_tensor\")\n",
        "print(to_tensor(cfds[0][0]).size())\n",
        "\n",
        "# callable class\n",
        "class ToTensor:\n",
        "    def __call__(self, image):\n",
        "        image = image.copy().astype(\"float32\")\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C\n",
        "        # torch image: C x H x W\n",
        "        image = image.transpose((2, 0, 1)) / 255\n",
        "        return torch.from_numpy(image)\n",
        "\n",
        "# create an object\n",
        "tensor_transform = ToTensor()\n",
        "print(\"ToTensor\")\n",
        "# the object is callable\n",
        "print(tensor_transform(cfds[0][0]).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYxTtq6yXAK9"
      },
      "source": [
        "For writing transforms that need an argument, we have a few different ways around it:\n",
        " - currying functions\n",
        " - callable classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6oP9_gvYJQ0"
      },
      "source": [
        "# transform for flipping\n",
        "\n",
        "def flip(horizontal=False, vertical=False):\n",
        "\n",
        "    # this is actually the function that will become the transform\n",
        "    def _flip(image):\n",
        "        image = image.copy()\n",
        "        if horizontal:\n",
        "            image = np.fliplr(image)\n",
        "        if vertical:\n",
        "            image = np.flipud(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "    # the outer function returns this function\n",
        "    return _flip\n",
        "\n",
        "# example call\n",
        "print(\"flip\")\n",
        "orig = cfds[0][0]\n",
        "flipped = flip(horizontal=True, vertical=False)(cfds[0][0])\n",
        "plt.imshow(np.hstack([orig, flipped])[:,:,::-1])\n",
        "plt.show()\n",
        "\n",
        "class Flip:\n",
        "    def __init__(self, horizontal=False, vertical=False):\n",
        "        self.horizontal = horizontal\n",
        "        self.vertical = vertical\n",
        "    \n",
        "    def __call__(self, image):\n",
        "        image = image.copy()\n",
        "        if self.horizontal:\n",
        "            image = np.fliplr(image)\n",
        "        if self.vertical:\n",
        "            image = np.flipud(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "# example call\n",
        "print(\"Flip\")\n",
        "orig = cfds[1][0]\n",
        "flipped = Flip(horizontal=True, vertical=False)(cfds[1][0])\n",
        "plt.imshow(np.hstack([orig, flipped])[:,:,::-1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk67g3fAcSBi"
      },
      "source": [
        "Most of the transformations are already implemented in `torch`.\n",
        "A very important one is `transforms.Compose`\n",
        "\n",
        "It simply takes a list of transforms and applies them in order"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8XdZye9bCpN"
      },
      "source": [
        "# Training a model\n",
        "\n",
        "Now, we'll train a `torch` model that uses this dataset. For augmentation, we'll be doing horizontal flips.\n",
        "\n",
        "For flowing the dataset through our model, while we can use a simple `for` loop, it won't have a lot of features like:\n",
        " - Batching the data\n",
        " - Shuffling the data\n",
        " - Load the data in parallel using `multiprocessing` workers\n",
        "\n",
        "`torch.utils.data.DataLoader` is an iterator which provides all these features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9kOeS7ncqN1"
      },
      "source": [
        "# @title Hyperparams {\"run\": \"auto\"}\n",
        "n_epochs = 100# @param {\"type\":\"integer\"}\n",
        "batch_size = 1024# @param {\"type\":\"integer\"}\n",
        "learning_rate = 1e-3# @param {\"type\": \"number\"}\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optim_fn = optim.Adam\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Sq5fLh3gdE1"
      },
      "source": [
        "class CIFAR10Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(in_features=3072, out_features=1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=1024, out_features=512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=512, out_features=128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=128, out_features=32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=32, out_features=10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvGOqW4JjPvS"
      },
      "source": [
        "def train(model, train_loader, n_epochs, lr, criterion, optim_fn, device):\n",
        "    model = model.to(device)\n",
        "    optimizer = optim_fn(model.parameters(), lr)\n",
        "    loss_history = []\n",
        "\n",
        "    with tqdm(range(n_epochs)) as prog_bar:\n",
        "        for epoch in prog_bar:\n",
        "            epoch_loss = 0\n",
        "    \n",
        "            # we are ignoring the labels\n",
        "            for images, labels_numeric, _ in train_loader:\n",
        "                # move to correct device and flatten the image\n",
        "                x = images.to(device).view(images.size(0), -1)\n",
        "                y = labels_numeric.to(device)\n",
        "                optimizer.zero_grad()\n",
        "    \n",
        "                # the prediction\n",
        "                out = model(x)\n",
        "    \n",
        "                loss = criterion(out, y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "    \n",
        "                epoch_loss += loss\n",
        "            \n",
        "            epoch_loss /= len(train_loader)\n",
        "            prog_bar.set_description(f\"loss: {epoch_loss}\")\n",
        "            loss_history.append(epoch_loss.detach())\n",
        "    \n",
        "    return loss_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DVxo3hpmbYX"
      },
      "source": [
        "cifar10_ds = CIFAR10Dataset(transforms=transforms.Compose([\n",
        "    # horizontal flip\n",
        "    # Note that this is not actually an augmentation since __all__ the images\n",
        "    #   are being flipped.\n",
        "    #\n",
        "    # Excercise: modify `Flip` to accept a probability for flipping at random\n",
        "    Flip(horizontal=True),\n",
        "    ToTensor(),\n",
        "]))\n",
        "\n",
        "train_dl = DataLoader(cifar10_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "model = CIFAR10Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbEGlGuGjkj2"
      },
      "source": [
        "loss_history = train(model, train_dl, n_epochs, learning_rate, loss_fn, optim_fn, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMS89PM4r3Jf"
      },
      "source": [
        "plt.plot(loss_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc-ZKBolvo1h"
      },
      "source": [
        "# Excercises\n",
        "Modify the `Flip` transform to accept a probability for flipping the image randomly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vZSEL8E2oZU"
      },
      "source": [
        "# References\n",
        " - https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        " - https://www.cs.toronto.edu/~kriz/cifar.html"
      ]
    }
  ]
}
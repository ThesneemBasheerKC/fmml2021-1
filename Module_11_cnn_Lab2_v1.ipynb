{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn-lab2_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fathimath-Rifna-VK/fmml2021/blob/main/Module_11_cnn_Lab2_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQqIVNVYnA90"
      },
      "source": [
        "# Convolutional Neural Networks - Lab 2\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        " <td>\n",
        " <a target=\"_blank\" href=\"https://colab.research.google.com/drive/14lRNogX_yUQI9abkUwZBFqvWiqNcVGf3?usp=sharing\"><img height=\"32px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" />Run in Google Colab</a>\n",
        " </td>\n",
        " <td>\n",
        " <a target=\"_blank\" href=\"https://github.com/Foundations-in-Modern-Machine-Learning/course-contents/blob/main/CNN/cnn_lab2.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        " </td>\n",
        "</table>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "---\n",
        "Module Coordinator: Ekta Gavas\n",
        "\n",
        "Email: ekta.gavas@research.iiit.ac.in\n",
        "\n",
        "\n",
        "## Description\n",
        "---\n",
        "In this lab exercise, we will understand how stacking smaller filters is beneficial. Further, we will study a simple image classification problem using CNNs. We will implement a basic CNN model for classifying grayscale MNIST images and train it end-to-end and evaluate our model on test data.\n",
        "\n",
        "## Starter Code\n",
        "---\n",
        "To make your task easier, we provide you the starter code to perform the lab exercises. It is expected that you should try to understand what the code does and analyze the output. We will be using Pytorch framework for the implementation of this lab. The training hyperparameters that are used in the code may not be the best to minimize training time according to lab scope. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2MGZmZZTXkg"
      },
      "source": [
        "## Stacking convolution layers vertically\n",
        "\n",
        "Normally, stack of small filter convolutions are preferred compared to large filter convolutions. Suppose that you stack two 3x3 CONV layers on top of each other (with non-linearities in between, of course). In this arrangement, each neuron on the first CONV layer has a 3x3 view of the input volume. A neuron on the second CONV layer has a 3x3 view of the first CONV layer, and hence by extension a 5x5 view of the input volume. Intuitively, stacking CONV layers with tiny filters as opposed to having one CONV layer with big filters allows us to express more powerful features of the input, and with fewer parameters.\n",
        "\n",
        "<img src='https://images.storychief.com/account_16771/7_e077bca1064609d5e4390df9f6de7384_1600.png' height=300px width=700px/>\n",
        "\n",
        "Image reference:https://www.sicara.ai/blog/2019-10-31-convolutional-layer-convolution-kernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53e-fecCLewH"
      },
      "source": [
        "# Import packages\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfEuvm4iNMsE"
      },
      "source": [
        "Now, we will see the result of convolving a 5x5 edge filter on the image in one case and convolving two 3x3 edge filters in one after the other.\n",
        "Below is the same function to apply given kernel to image, which we implemented at first in the previous lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x80iYA2L26N"
      },
      "source": [
        "def apply_filter(img, filter):\n",
        "  height, width = img.shape\n",
        "  filter_size = filter.shape\n",
        "\n",
        "  output = np.empty(0)\n",
        "\n",
        "  # Move the filter over entire image and store the result in output\n",
        "  for i in range(0, height - filter_size[1] + 1):\n",
        "    for j in range(0, width - filter_size[0] + 1):\n",
        "      # Matrix multiplication for a single patch of image and filter\n",
        "      output = np.append(output, np.sum(np.multiply(img[i:i+filter_size[0], j:j+filter_size[1]], filter)))\n",
        "  \n",
        "  # Calculate the output shape of the resultant image\n",
        "  output_shape = (height - (filter_size[1]-1)), (width - (filter_size[0]-1))\n",
        "\n",
        "  # Return the reshaped image\n",
        "  return output.reshape(output_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc1IlzznLwto"
      },
      "source": [
        "# Get the sample image\n",
        "!curl -L -o 'lotus.jpg' 'https://drive.google.com/uc?export=download&id=1gQSQlrUws22KLRUacXwvN1G8FtIyhfGt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr4YjfkNJGd9"
      },
      "source": [
        "Now, let's apply the convolutions to image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK5y8RS5T3Si"
      },
      "source": [
        "# Read the image with opencv, 0 stands for 'grayscale'\n",
        "image = cv2.imread('lotus.jpg', 0)\n",
        "\n",
        "# 5 x 5 Vertical edge filter\n",
        "filter5 = np.array([[1, 1, 0,-1, -1],\n",
        "                   [1, 1, 0,-1, -1],\n",
        "                   [1, 1, 0,-1, -1],\n",
        "                   [1, 1, 0,-1, -1],\n",
        "                   [1, 1, 0,-1, -1]])\n",
        "\n",
        "# Apply the 5x5 filter to image\n",
        "output1 = apply_filter(image, filter5)\n",
        "\n",
        "\n",
        "filter3 = np.array([[1,0,-1],\n",
        "                   [1,0,-1],\n",
        "                   [1,0,-1]])\n",
        "\n",
        "# Apply 3x3 filter to image and again, apply the same filter to the output\n",
        "output2 = apply_filter(image, filter3)\n",
        "output2 = apply_filter(output2, filter3)\n",
        "\n",
        "\n",
        "# Plot results\n",
        "fig = plt.figure(figsize=(10,9))\n",
        "ax = fig.add_subplot(1,3,1)\n",
        "ax.imshow(image, cmap='gray')\n",
        "ax.set_title('Original Image - '+str(image.shape))\n",
        "\n",
        "ax = fig.add_subplot(1,3,2)\n",
        "ax.imshow(output1, cmap='gray')\n",
        "ax.set_title('One 5x5 Conv - '+str(output1.shape))\n",
        "\n",
        "ax = fig.add_subplot(1,3,3)\n",
        "ax.imshow(output2, cmap='gray')\n",
        "ax.set_title('Two 3x3 stacked Conv - '+str(output2.shape))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV4szxQAOEKA"
      },
      "source": [
        "As you can see, the output image size in both the cases is the same and the edges in the second case are detected more appropriately. Now, let's also calculate the number of parameters in both cases. The parameters are less in the stack of filters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeB4XiaGV2aT"
      },
      "source": [
        "print('Number of parameters in 5x5 Conv: ', str(5*5))\n",
        "print('Number of parameters in equivalent 3x3 stacked Conv: ', str((3*3) * 2)) #stack of 2 filters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewhnwh1P6aAk"
      },
      "source": [
        "## MNIST Digit Classification\n",
        "\n",
        "<img src='https://miro.medium.com/max/1872/1*SGPGG7oeSvVlV5sOSQ2iZw.png' />\n",
        "\n",
        "Image reference: https://miro.medium.com/max/1872/1*SGPGG7oeSvVlV5sOSQ2iZw.png\n",
        "\n",
        "We will be implementing a CNN model which can predict the digit, given a grayscale image. The architecture of model is given in the above image.\n",
        "\n",
        "**We will do the following steps in order:**\n",
        "1.   Load and visualize MNIST training and test datasets using torchvision\n",
        "2.   Define the CNN model\n",
        "3.   Define a loss function and optimizer\n",
        "4.   Train the network on the training data\n",
        "5.   Evaluate the network on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWJa9NQvSdr8"
      },
      "source": [
        "# Import packages\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhYuybK767Sa"
      },
      "source": [
        "# Device configuration (whether to run on GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZMFwB08ZvSN"
      },
      "source": [
        "# Set seeds for reproducibility\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ0n6wa47uZu"
      },
      "source": [
        "#### Load MNIST data\n",
        "We will use the [MNIST dataset](https://pytorch.org/vision/stable/datasets.html#mnist) from torchvision Pytorch and setup the train and test dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr2uSnxn7nIb"
      },
      "source": [
        "batch_size_train = 128\n",
        "batch_size_test = 128\n",
        "\n",
        "# Images in torchvision datasets are PIL Images in range [0,1] so we need\n",
        "# 'ToTensor' transform to convert them into tensors\n",
        "train_data = torchvision.datasets.MNIST('./data', train=True, download=True,\n",
        "                             transform=torchvision.transforms.ToTensor())\n",
        "test_data = torchvision.datasets.MNIST('./data', train=False, download=True,\n",
        "                             transform=torchvision.transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size_train, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size_test, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HRj26o673We"
      },
      "source": [
        "#### Understand the dataset\n",
        "Let us now visualize the dataset in terms of number of samples, classes etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwP6Weyr7wZb"
      },
      "source": [
        "print('Training data shape : ', train_data.data.shape, train_data.targets.shape)\n",
        "print('Testing data shape : ', test_data.data.shape, test_data.targets.shape)\n",
        "\n",
        "# Find the unique numbers from the train labels\n",
        "classes = np.unique(train_data.targets.numpy())\n",
        "nClasses = len(classes)\n",
        "print('Total number of outputs : ', nClasses)\n",
        "print('Output classes : ', classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43ZzTl-078NJ"
      },
      "source": [
        "# Helper function to plot data\n",
        "def plot_data(images, labels, classes=None):\n",
        "  figure = plt.figure(figsize=(9, 4))\n",
        "  cols, rows = 5, 2\n",
        "  for i in range(1, cols * rows + 1):\n",
        "      sample_idx = torch.randint(len(images), size=(1,)).item()\n",
        "      img, label = images[sample_idx], labels[sample_idx]\n",
        "      figure.add_subplot(rows, cols, i)\n",
        "      if classes is not None:\n",
        "        label = classes[label]\n",
        "      plt.title('Label:' +str(label))\n",
        "      plt.axis(\"off\")\n",
        "      plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1bnP8EyqktD"
      },
      "source": [
        "plot_data(train_data.data, train_data.targets.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYYNFnPk8LWD"
      },
      "source": [
        "#### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-e1DrVT8GYt"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)                          \n",
        "        self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # fully connected layer\n",
        "        self.fc = nn.Linear(64 * 7 * 7, 128)\n",
        "        # output layer 10 classes\n",
        "        self.out = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x) #activation\n",
        "        x = self.max_pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.max_pool2(x)\n",
        "        # flatten the output for FC layer\n",
        "        x = x.view(x.size(0), -1)       \n",
        "        x = self.fc(x)\n",
        "        output = self.out(x)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqoGCFWd8RRG"
      },
      "source": [
        "# Build the model object and put on the device\n",
        "model = CNN().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux_2PGgT8diG"
      },
      "source": [
        "#### Define Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZDAwCNb8VER"
      },
      "source": [
        "# Cross Entropy loss for multi-class classification\n",
        "loss_func = nn.CrossEntropyLoss()   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fwSTPmI8lQP"
      },
      "source": [
        "#### Define optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GieENlOa8heQ"
      },
      "source": [
        "# Basic SGD optimizer with 0.01 learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svJ3-UB187qa"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t94F0wxMefKz"
      },
      "source": [
        "Helper function for training/testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDXNReyi8n5o"
      },
      "source": [
        "def train(num_epochs, model, train_loader, loss_func, optimizer):\n",
        "\n",
        "  # Training mode\n",
        "  model.train()\n",
        "\n",
        "  train_losses = []\n",
        "  train_acc = []\n",
        "\n",
        "  # Train the model\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    running_acc = 0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "      \n",
        "      # clear gradients for this training step   \n",
        "      optimizer.zero_grad()           \n",
        "\n",
        "      # Put data on devices\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Forward pass\n",
        "      output = model(images)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = loss_func(output, labels)\n",
        "\n",
        "      # Backpropagation, compute gradients \n",
        "      loss.backward()\n",
        "\n",
        "      # Apply gradients             \n",
        "      optimizer.step()                \n",
        "      \n",
        "      # Running loss\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      # indices of max probabilities\n",
        "      _, preds = torch.max(output, dim=1)\n",
        "\n",
        "      # Calculate number of correct predictions\n",
        "      correct = (preds.float() == labels).sum()\n",
        "      running_acc += correct\n",
        "\n",
        "      epoch_loss = running_loss / len(train_loader.dataset)\n",
        "      epoch_acc = running_acc / len(train_loader.dataset)\n",
        "\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_acc.append(epoch_acc)\n",
        "    print ('Epoch {}/{}, Loss: {:.4f}, Accuracy: {:.4f}'.format(epoch + 1, num_epochs, epoch_loss, epoch_acc*100))\n",
        "\n",
        "  return train_losses, train_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFYI98OtNjCc"
      },
      "source": [
        "def test(model, test_loader):\n",
        "  # Eval mode\n",
        "  model.eval()\n",
        "  test_acc = 0\n",
        "  correct = 0\n",
        "  for i, (images, labels) in enumerate(test_loader):\n",
        "    # Deactivate autograd engine (don't compute grads since we're not training)\n",
        "    with torch.no_grad():\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      output = model(images)\n",
        "\n",
        "      # Calculate number of correct predictions\n",
        "      _, preds = torch.max(output, dim=1)\n",
        "      correct += (preds == labels).sum()\n",
        "\n",
        "  test_acc = correct / len(test_loader.dataset)\n",
        "  print('Test Accuracy: {:.4f}'.format(test_acc*100))\n",
        "\n",
        "  # Plot the images with predicted labels\n",
        "  plot_data(images.data.cpu().numpy(), preds.data.cpu().numpy(), test_loader.dataset.classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6pYjXgchc3E"
      },
      "source": [
        "Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax9XMoe5H_ik"
      },
      "source": [
        "num_epochs = 10  # iterations\n",
        "train_losses, train_acc = train(num_epochs, model, train_loader, loss_func, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6ltVbRI4dr6"
      },
      "source": [
        "Plot training plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPJHC1_tIFAr"
      },
      "source": [
        "fig = plt.figure(figsize=(10,4))\n",
        "ax = fig.add_subplot(1,2, 1)\n",
        "ax.plot(np.arange(1,len(train_losses)+1),train_losses)\n",
        "plt.xlabel('Training loss')\n",
        "plt.ylabel('Epochs')\n",
        "ax.set_title('Loss vs Epochs')\n",
        "ax = fig.add_subplot(1,2, 2)\n",
        "ax.plot(np.arange(1,len(train_acc)+1),train_acc)\n",
        "plt.xlabel('Training accuracy')\n",
        "plt.ylabel('Epochs')\n",
        "ax.set_title('Accuracy vs Epochs')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYW-_wTfWvYl"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rReuhwjpXr5K"
      },
      "source": [
        "# Evaluate the model on testing data and plot predictions\n",
        "test(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puMO_nSBmUFq"
      },
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfozvSgV_mt5"
      },
      "source": [
        "Q 1: What is the ratio of parameters in single 5 x 5 kernel and equivalent stacked 3 x 3 kernels? Consider number of channels in input and output channels as C."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7LXbTpZnbT0"
      },
      "source": [
        "Q 2: How can you replace 7 x 7 convolution kernel using only 3 x 3 kernels? What would be ratio of parameters in this case? Consider number of channels in input and output channels as C.\n",
        "\n",
        "Answer: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTEFXKr0mhQ2"
      },
      "source": [
        "Q 3: Can you guess what can happen if the output of each convolution layer is not Relu activated? In other sense, can you state the importance of Relu activation at each layer?\n",
        "(Hint: You can comment those two lines in the forward function and check if your guess was right!)\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE96iUAjXMhc"
      },
      "source": [
        "Q 4: Calculate the layerwise number of parameters in the MNIST CNN network. Ignore the bias parameters. Which layer does not have any learnable parameters?\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JifqJYlYijbp"
      },
      "source": [
        "Q 5: For the below image, what is the ratio of the number of parameters if we use a fully connected layer compared to a convolutional layer?\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1Chi7puquqg_3hyVATDeLgMBZIzFv79E2' height=200/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujQ-YTLqBfKW"
      },
      "source": [
        "### Bonus Question\n",
        "Perform image classification for Fashion MNIST dataset from Pytorch. You can copy paste the code in below cells for the data loading and visualization, model and training from above. You just need to replace the dataset class 'MNIST' with '[FashionMNIST](https://pytorch.org/vision/stable/datasets.html#fashion-mnist)' and keep the hyperparameters the same. Comment on the model performance. Can you improve it further?\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv0PCCC9GtBG"
      },
      "source": [
        "## References and Additional Resources:\n",
        "\n",
        "\n",
        "*   [About Convolutional Layer and Convolution Kernel](https://www.sicara.ai/blog/2019-10-31-convolutional-layer-convolution-kernel)\n",
        "*   [MNIST digit classification in Pytorch](https://nextjournal.com/gkoehler/pytorch-mnist)\n",
        "*   [CNNs - (Advanced)](https://cs231n.github.io/convolutional-networks/)\n",
        "*   [Torchvision Datasets](https://pytorch.org/vision/stable/datasets.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMs8DEzLCrYO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
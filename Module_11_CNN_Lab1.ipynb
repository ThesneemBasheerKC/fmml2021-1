{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-Lab1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fathimath-Rifna-VK/fmml2021/blob/main/Module_11_CNN_Lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQqIVNVYnA90"
      },
      "source": [
        "# Convolutional Neural Networks - Lab 1\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        " <td>\n",
        " <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1WZWRO4HLHoAnX6yAq-93_GPEVwb5bkFA\"><img height=\"32px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" />Run in Google Colab</a>\n",
        " </td>\n",
        " <td>\n",
        " <a target=\"_blank\" href=\"https://github.com/Foundations-in-Modern-Machine-Learning/course-contents/blob/main/CNN/cnn_lab1.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        " </td>\n",
        "</table>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "---\n",
        "Module Coordinator: Ekta Gavas\n",
        "\n",
        "Email: ekta.gavas@research.iiit.ac.in\n",
        "\n",
        "## Description\n",
        "---\n",
        "In this lab exercise, we will examine the role of convolutions, starting with very basic examples of using popular filters like horizontal and vertical edge filters on grayscale images. We will also study various operations like convolution, strides, pool and padding by building our own function step-by-step *apply_filter()* to apply filter on image, with varying strides and padding. Then, we will also explore Pytorch functions (*Conv2d, MaxPool2d, AvgPool2d*) for the same. Finally, we will see an example of applying convolution on an RGB image as well.\n",
        "\n",
        "Once you get a clear idea of how convolution works, you are required to complete a few simple exercises given at the end of this notebook.\n",
        "\n",
        "## Starter Code\n",
        "---\n",
        "To make your task easier, we provide you the starter code to perform the lab exercises. It is expected that you should try to understand what the code does and analyze the output. We will be using OpenCV (a library for image processing), NumPy for matrix and array operations, and Matplotlib for plotting the images. Later, we will use Pytorch framework to analyze the effect of strides, pooling etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei9WdB5Usrbf"
      },
      "source": [
        "Central to Convolutional Neural Networks (CNN), a convolution operation is a linear operation which involves element-wise multiplication between a small filter (say, a matrix of integers) and filter-sized patch from the image. We move this filter across the image like a sliding window from top left to bottom right. For each point on the image, a value is calculated based on the filter using a convolution operation. These filters can do simplest task like checking if there is a vertical line in the image or complicated task like detecting a human eye in the image. \n",
        "\n",
        "Let's look at the convolution formula:\n",
        "\n",
        "Convolution between image $f(x, y)$ and kernel $k(x, y)$ is\n",
        "$$f(x,y) * k(x,y) = \\sum \\limits _{i=0} ^{W-1} \\sum \\limits _{j=0} ^{H-1} f(i, j) k(x − i, y − j)$$\n",
        "\n",
        "where $W$ and $H$ are the the width and height of the image.\n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Chaim-Baskin/publication/318849314/figure/fig1/AS:614287726870532@1523469015098/Image-convolution-with-an-input-image-of-size-7-7-and-a-filter-kernel-of-size-3-3.png\" alt=\"Convolution\" width=650px height=280px/>\n",
        "\n",
        "\n",
        "Image reference: [Streaming Architecture for Large-Scale Quantized Neural Networks on an FPGA-Based Dataflow Platform](https://www.researchgate.net/publication/318849314_Streaming_Architecture_for_Large-Scale_Quantized_Neural_Networks_on_an_FPGA-Based_Dataflow_Platform/figures?lo=1)\n",
        "\n",
        "The code demonstrates the convolution operation of a 2D matrix (image) with various filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ7Jenl0iskd"
      },
      "source": [
        "### Convolution and Edge detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1BUpG9U6rXK"
      },
      "source": [
        "Let us first take a simplest case to detect vertical edge in image of the same size as the filter (say 3 x 3) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJQQyIFWkdJy"
      },
      "source": [
        "# Import packages\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyj8pgI16ej9"
      },
      "source": [
        "# 2D 3x3 binary image with vertical edge\n",
        "image1 = np.array([[1,1,0],\n",
        "                   [1,1,0],\n",
        "                   [1,1,0]])\n",
        "\n",
        "# 2D 3x3 binary image with horizontal edge\n",
        "image2 = np.array([[0,0,0],\n",
        "                   [0,0,0],\n",
        "                   [1,1,1]])\n",
        "\n",
        "# print(image1*255)\n",
        "# Let's plot the images\n",
        "fig = plt.figure(figsize=(10,4))\n",
        "ax = fig.add_subplot(1,2,1)\n",
        "ax.imshow(image1, cmap='gray', extent=[0, 3, 3, 0])\n",
        "# plt.ylim(0, 3)\n",
        "ax.set_title('Image 1 with vertical edge')\n",
        "\n",
        "ax = fig.add_subplot(1,2,2)\n",
        "ax.imshow(image2, cmap='gray', extent=[0, 3, 3, 0])\n",
        "ax.set_title('Image 2 with horizontal edge')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGZFq4O8-qql"
      },
      "source": [
        "Let's create a 3x3 vertical edge filter. We will 'convolve' this filter over the images to detect vertical edge. As the image is same size as of filter, this is simple element-wise multiplication and summing up the result into single value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2ralw9w7R0x"
      },
      "source": [
        "# Vertical Line filter\n",
        "filter = np.array([[1,0,-1],\n",
        "                   [1,0,-1],\n",
        "                   [1,0,-1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoWLcsu37jLq"
      },
      "source": [
        "# Applying filter to first image\n",
        "output = np.sum(np.multiply(image1, filter))\n",
        "print('Output from first image: ', output)\n",
        "\n",
        "# Applying filter to second image\n",
        "output = np.sum(np.multiply(image2, filter))\n",
        "print('Output from second image: ', output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvCvYI9c-MX4"
      },
      "source": [
        "Non-zero output suggests that there is a vertical edge present in the first image and not present in the second image.\n",
        "Now, let's create a horizontal edge filter and apply it to both the above images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl7h6HrJ8h5W"
      },
      "source": [
        "# Horizontal edge filter\n",
        "filter = np.array([[-1,-1,-1],\n",
        "                   [ 0, 0, 0],\n",
        "                   [ 1, 1, 1]])\n",
        "\n",
        "output = np.sum(np.multiply(image1, filter))\n",
        "print('Output from first image: ', output)\n",
        "\n",
        "output = np.sum(np.multiply(image2, filter))\n",
        "print('Output from second image: ', output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BWlGBDVWEDO"
      },
      "source": [
        "As expected, the horizontal edge is detected in second image with this filter. \n",
        "\n",
        "Now, we will take a bigger image (5 x 5) and see how a convolution operation works by sliding a filter left to right and top to bottom to obtain an output map from image. Let's define a function ***apply_filter()*** for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VszqKiZHsOXB"
      },
      "source": [
        "def apply_filter(img, filter):\n",
        "  height, width = img.shape\n",
        "  filter_size = filter.shape\n",
        "\n",
        "  output = np.empty(0)\n",
        "\n",
        "  # Move the filter over entire image and store the result in output\n",
        "  for i in range(0, height - filter_size[1] + 1):\n",
        "    for j in range(0, width - filter_size[0] + 1):\n",
        "      # Matrix multiplication for a single patch of image and filter\n",
        "      output = np.append(output, np.sum(np.multiply(img[i:i+filter_size[0], j:j+filter_size[1]], filter)))\n",
        "  \n",
        "  # Calculate the output shape of the resultant image\n",
        "  output_shape = (height - (filter_size[1]-1)), (width - (filter_size[0]-1))\n",
        "\n",
        "  # Return the reshaped image\n",
        "  return output.reshape(output_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y03Dtn3F0sp"
      },
      "source": [
        "Plotting function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mJqbXQZF0sq"
      },
      "source": [
        "def plot_images(images, titles, tick_params=True):\n",
        "  n = len(images)\n",
        "  fig = plt.figure(figsize=(10,4))\n",
        "  for i in range(n):\n",
        "    ax = fig.add_subplot(1,n,i+1)\n",
        "    if len(images[i].shape) == 2:\n",
        "      ax.imshow(images[i], cmap='gray', \n",
        "                extent=(0,images[i].shape[1], images[i].shape[0], 0))\n",
        "    else:\n",
        "      ax.imshow(images[i])\n",
        "    ax.set_title(titles[i])\n",
        "    if not tick_params:\n",
        "      plt.tick_params(axis='both', labelbottom=False, bottom=False, \n",
        "                labelleft=False, left=False)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpTLmPYG0Pom"
      },
      "source": [
        "# 2D image\n",
        "img = np.array([[20,20,0,0,0],\n",
        "                [20,20,0,0,0],\n",
        "                [20,20,0,0,0],\n",
        "                [20,20,0,0,0],\n",
        "                [20,20,0,0,0]])\n",
        "\n",
        "# Vertical edge filter\n",
        "filter = np.array([[1,0,-1],\n",
        "                   [1,0,-1],\n",
        "                   [1,0,-1]])\n",
        "\n",
        "\n",
        "output = apply_filter(img, filter)\n",
        "print(output) # Note the shape of output image!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-tmlp1qHA9f"
      },
      "source": [
        "# Let's plot the above image with results\n",
        "images = []\n",
        "titles = []\n",
        "\n",
        "images.append(img)\n",
        "titles.append('Original Image')\n",
        "\n",
        "images.append(filter)\n",
        "titles.append('Filter')\n",
        "\n",
        "images.append(output)\n",
        "titles.append('Convolution Output')\n",
        "\n",
        "plot_images(images, titles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmSCGzaYVFze"
      },
      "source": [
        "As, you can see, horizontal edge is detected in the output.\n",
        "\n",
        "Now, we will see the effect of applying this filter on a grayscale image. Again, for this, we need to 'convolve' the filter over the entire image.\n",
        "We will use the same filter and function defined earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjOQM6tdF0sr"
      },
      "source": [
        "# Get the sample image\n",
        "!curl -L -o 'lotus.jpg' 'https://drive.google.com/uc?export=download&id=1gQSQlrUws22KLRUacXwvN1G8FtIyhfGt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04P_GfojIo4u"
      },
      "source": [
        "# Read the image with opencv, 0 stands for 'grayscale'\n",
        "image = cv2.imread('lotus.jpg', 0)\n",
        "print('Original image size: ', image.shape)\n",
        "\n",
        "# Saving images for plots\n",
        "images = []\n",
        "titles = []\n",
        "\n",
        "images.append(image)\n",
        "titles.append('Original Image')\n",
        "\n",
        "# Vertical edge filter\n",
        "filter = np.array([[1,0,-1],\n",
        "                   [1,0,-1],\n",
        "                   [1,0,-1]])\n",
        "\n",
        "images.append(filter)\n",
        "titles.append('Filter')\n",
        "\n",
        "# Apply this filter to image\n",
        "output = apply_filter(image, filter)\n",
        "\n",
        "print('Output image size: ', output.shape)\n",
        "\n",
        "images.append(output)\n",
        "titles.append('Convolution Output')\n",
        "\n",
        "# Let's plot the images\n",
        "plot_images(images, titles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atgZGTMzb-ax"
      },
      "source": [
        "The convolved outputs in both the above cases, is smaller than the original image. To get the result of same size, we use padding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gck3hUjhI5gU"
      },
      "source": [
        "### Padding\n",
        "\n",
        "We noted that the output image after convolution is smaller than the original. Here, we will understand the use of padding to get the image same as original size. We will modify the earlier function ***apply_filter()*** to pad the image first with 0s and then apply convolution. We can also extend our image by filling it with 0s but here we will see the use cv2.copyMakeBorder() from OpenCV for padding. Refer [Making Borders for Images (Padding)](https://docs.opencv.org/3.1.0/d3/df2/tutorial_py_basic_ops.html) for more information on the usage of this function. ***Just note the change in the function below.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nImyUsCXJAgS"
      },
      "source": [
        "def apply_filter(img, filter, padding=0):\n",
        "  height, width = img.shape\n",
        "\n",
        "  # Note the change below\n",
        "  # Below function makes a border (padding) with zeros around image\n",
        "  img = cv2.copyMakeBorder(img, padding,padding,padding,padding, cv2.BORDER_CONSTANT,value=[0])\n",
        "\n",
        "  print('Image after padding: \\n', img)\n",
        "\n",
        "  new_height, new_width = img.shape\n",
        "  filter_size = filter.shape\n",
        "\n",
        "  output = np.empty(0)\n",
        "\n",
        "  # Move the filter over entire image and store the result in output\n",
        "  for i in range(0, new_height - filter_size[1] + 1):\n",
        "    for j in range(0, new_width - filter_size[0] + 1):\n",
        "      # Matrix multiplication for a single patch of image and filter\n",
        "      output = np.append(output, np.sum(np.multiply(img[i:i+filter_size[0], j:j+filter_size[1]], filter)))\n",
        "  \n",
        "  # Calculate the output shape of the resultant image\n",
        "  output_shape = (height - (filter_size[1]-1) + 2*padding), (width - (filter_size[0]-1) + 2*padding) # Note the change in formula\n",
        "\n",
        "  # Return the reshaped image\n",
        "  return output.reshape(output_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M-2_MRbJe6F"
      },
      "source": [
        "img = np.array([[20,20,0,0,0],\n",
        "                [20,20,0,0,0],\n",
        "                [20,20,0,0,0],\n",
        "                [20,20,0,0,0],\n",
        "                [20,20,0,0,0]])\n",
        "o = apply_filter(img, filter,1)\n",
        "\n",
        "print('Output image: \\n', o)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWs92BTYOVGV"
      },
      "source": [
        "Thus, we used padding to get output image size same as that of original image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9zuAg-TO10t"
      },
      "source": [
        "### Stride\n",
        "\n",
        "Strides determine the number of units to shift while moving a filter over an image. To understand the working of strides, we will again modify the earlier function ***apply_filter()*** to incorporate the stride value. By default, the stride value was 1 earlier as we were shifting the filter one element in any direction. ***Just note the change in the function below.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsW4IZyvO4Ei"
      },
      "source": [
        "def apply_filter(img, filter, padding=0, stride=1):\n",
        "  height, width = img.shape\n",
        "\n",
        "  # Below function makes a border (padding) with zeros around image\n",
        "  img = cv2.copyMakeBorder(img, padding,padding,padding,padding, cv2.BORDER_CONSTANT,value=[0])\n",
        "\n",
        "  new_height, new_width = img.shape\n",
        "  filter_size = filter.shape\n",
        "\n",
        "  output = np.empty(0)\n",
        "\n",
        "  # Move the filter over entire image and store the result in output\n",
        "  for i in range(0, new_height - filter_size[1] + 1, stride):          # Note the change here\n",
        "    for j in range(0, new_width - filter_size[0] + 1, stride):         # Note the change here\n",
        "      # Matrix multiplication for a single patch of image and filter\n",
        "      output = np.append(output, np.sum(np.multiply(img[i:i+filter_size[0], j:j+filter_size[1]], filter)))\n",
        "  \n",
        "  # Calculate the output shape of the resultant image\n",
        "  output_shape = (((height - (filter_size[1]-1) + 2*padding -1) // stride)+1,\n",
        "                  ((width - (filter_size[0]-1) + 2*padding -1)// stride)+1) # Note the change in formula!\n",
        "\n",
        "  # Return the reshaped image\n",
        "  return output.reshape(output_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMgLLo0FQW3j"
      },
      "source": [
        "img = np.array([[20,20,0,0,0],\n",
        "                [20,20,0,0,0],\n",
        "                [20,20,0,0,0],\n",
        "                [20,20,0,0,0],\n",
        "                [20,20,0,0,0]])\n",
        "o = apply_filter(img, filter,padding=0, stride=2)\n",
        "\n",
        "print('Output image: \\n', o)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXyCz672RfXP"
      },
      "source": [
        "Thus, increasing the stride value decreases the output size further as we skip calculating some values. We will now see the effect of increasing strides, padding and kernel size on output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HjQRq6bVNtG"
      },
      "source": [
        "#### Effect of padding, kernel size and stride\n",
        "Instead of a convolution function we built earlier for applying filter/kernel to image, we will directly use convolution layer in the **Pytorch** framework. Refer [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) for more information about additional parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RKg8qtjP6af"
      },
      "source": [
        "# Import pytorch packages\n",
        "import torch\n",
        "from torch.nn import Conv2d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBcuce2bF0su"
      },
      "source": [
        "##### Convolution in pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRmaXjhVCrdJ"
      },
      "source": [
        "We will define a helper function to create an square vertical edge filter of given size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX6K7F6-dHhf"
      },
      "source": [
        "def generate_filter(k=3):\n",
        "  kernel = np.ones((k, k))\n",
        "  mid_index = k // 2\n",
        "  kernel[:, mid_index].fill(0)\n",
        "  kernel[:, mid_index+1:] *= -1\n",
        "  return kernel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X25gwS1GgMGY"
      },
      "source": [
        "We will create a helper function that takes one of the kernel elements, create a Convolution layer using pytorch and return the output image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a6_FwTsgZ49"
      },
      "source": [
        "def apply_conv(image, kernel_size, padding=0, stride=1):\n",
        "\n",
        "  #--------IMAGE PREPROCESSING-------\n",
        "  # Convert image to tensor from numpy\n",
        "  image = torch.from_numpy(image)\n",
        "  # Pytorch requires input to convolution in (N,C,H,W), where N = batch size and C=#channels in input\n",
        "  input = image.view((1,1,image.shape[0], image.shape[1]))\n",
        "\n",
        "  # --------------KERNEL-------------\n",
        "  # Create a nxn kernel\n",
        "  kernel = generate_filter(kernel_size)\n",
        "\n",
        "  # Create a tensor from the numpy array\n",
        "  kernel = torch.from_numpy(kernel.astype(np.float32))\n",
        "\n",
        "  # Pytorch requires kernel of shape (N,C,H,W), where N = batch size and C=#channels in input\n",
        "  kernel = kernel.view((1,1,kernel.shape[0], kernel.shape[1]))\n",
        "\n",
        "  # ---------CONVOLUTION LAYER--------\n",
        "  #1 input image channel, 1 output channels, nxn square convolution with padding on all 4 sides\n",
        "  conv = Conv2d(in_channels=1, out_channels=1, kernel_size=kernel.shape, padding=padding, stride=stride)\n",
        "\n",
        "  # Set the kernel weights in the convolution layer\n",
        "  conv.weight = torch.nn.Parameter(kernel)\n",
        "  \n",
        "  # ---------APPLY CONVOLUTION--------\n",
        "  output = conv(input / 255.)  # Getting input from 0 to 1\n",
        "  output_img = output.data.numpy()  # Tensor to back in numpy\n",
        "  output_img = output_img.reshape((-1, output_img.shape[-1])) # Reshape to 2D image\n",
        "\n",
        "  return output_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6-_WvVRdp6l"
      },
      "source": [
        "##### Effect of Padding\n",
        "Change the padding value with the slider. What do you observe?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehT5KaDJeESD"
      },
      "source": [
        "#@title Effect of padding { run: \"auto\", vertical-output: true, display-mode: \"both\" }\n",
        "\n",
        "# Note:After running this cell manually, it will auto-run if you \n",
        "# change the selected value.\n",
        "\n",
        "# Our original lotus image\n",
        "image = cv2.imread('lotus.jpg', 0)\n",
        "\n",
        "\n",
        "# Apply 3x3 convolution to image with given padding 1 on all 4 sides\n",
        "padding = 9 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "n = apply_conv(image, 3, padding=padding)\n",
        "\n",
        "# Plot the results\n",
        "plt.imshow(n, cmap='gray')\n",
        "plt.title('Padding={}\\nShape: {}'.format(padding, str(n.shape)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyFlTUw7exTI"
      },
      "source": [
        "As you observed, the output shape changes with padding. More the padding, bigger will be the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVThLy3OfBi4"
      },
      "source": [
        "##### Effect of Kernel size\n",
        "Change the kernel size with the slider. What do you observe?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYoc2xwTlBj_"
      },
      "source": [
        "#@title Effect of Kernel size { run: \"auto\", vertical-output: true, display-mode: \"both\" }\n",
        "# Our original lotus image\n",
        "image = cv2.imread('lotus.jpg', 0)\n",
        "\n",
        "# Apply 3x3 convolution to image\n",
        "K = 7 #@param {type:\"slider\", min:3, max:21, step:2}\n",
        "n = apply_conv(image, K)\n",
        "\n",
        "# Plot result\n",
        "plt.imshow(n, cmap='gray')\n",
        "plt.title('K = {}\\nShape = {}'.format(K, str(n.shape)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oKNN4gBnzOc"
      },
      "source": [
        "Thus, we conclude that output image becomes blurry with increase in kernel size as summation occurs over larger neighbourhood. Smaller kernel size is used to capture details whereas larger kernel captures bigger elements in image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DJoZNQOmlT3"
      },
      "source": [
        "##### Effect of Stride\n",
        "Change the stride value with the slider. What do you observe?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zISU25SBj1O7"
      },
      "source": [
        "#@title Effect of Stride { run: \"auto\", vertical-output: true, display-mode: \"both\" }\n",
        "# Our original lotus image\n",
        "image = cv2.imread('lotus.jpg', 0)\n",
        "\n",
        "# Apply 3x3 convolution to image\n",
        "stride = 2 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "n = apply_conv(image, 3, stride=stride)\n",
        "\n",
        "# Plot result\n",
        "plt.imshow(n, cmap='gray')\n",
        "plt.title('Stride = {}\\nShape = {}'.format(stride, str(n.shape)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNSTgzuYoY29"
      },
      "source": [
        "As we can see, the output becomes pixelated as strides increase because we have fewer values in the output by skipping pixels in input. Also, hence size of output decreases. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWI03dYYR2xf"
      },
      "source": [
        "### Pooling\n",
        "Strides, actually downsample the image but a more robust and common approach is pooling. It may be useful when we do not require finer details but important structural elements. Here, we will see an example of max pooling and average pooling on a simple 2D image matrix. Refer [nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) and [nn.AvgPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html) for the documentation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVOCZ80mnrdf"
      },
      "source": [
        "Max Pooling & Average Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD1mlfc8JOjs"
      },
      "source": [
        "from torch.nn import MaxPool2d, AvgPool2d\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 2D image\n",
        "image = np.array([\n",
        "    [2, 0, 0, 1, 6, 0, 5, 3],\n",
        "\t\t[0, 6, 5, 9, 1, 5, 8, 0],\n",
        "\t\t[0, 6, 0, 1, 2, 3, 4, 4],\n",
        "\t\t[7, 0, 3, 1, 4, 2, 0, 1],\n",
        "\t\t[3, 7, 0, 5, 6, 0, 5, 0],\n",
        "\t\t[0, 4, 6, 1, 1, 0, 0, 1],\n",
        "\t\t[3, 5, 0, 2, 2, 0, 9, 0],\n",
        "\t\t[1, 0, 3, 1, 7, 0, 0, 0]])\n",
        "\n",
        "# Saving output for plots\n",
        "output = []\n",
        "titles = []\n",
        "\n",
        "output.append(image)\n",
        "titles.append('Image')\n",
        "\n",
        "image = torch.from_numpy(image.astype(np.float32))\n",
        "input = image.view((1,1,image.shape[0], image.shape[1]))\n",
        "\n",
        "#----------MAX POOLING LAYER--------\n",
        "pool_layer = MaxPool2d(kernel_size=4, stride=4)\n",
        "op = pool_layer(input)\n",
        "max_output_img = op.data.numpy()  # Tensor to back in numpy\n",
        "max_output_img = max_output_img.reshape((-1, max_output_img.shape[-1]))\n",
        "print('Max Pooling:\\n', max_output_img)\n",
        "print()\n",
        "output.append(max_output_img)\n",
        "titles.append('Max Pool output')\n",
        "\n",
        "#----------AVERAGE POOLING LAYER--------\n",
        "pool_layer = AvgPool2d(kernel_size=4, stride=4)\n",
        "op = pool_layer(input)\n",
        "avg_output_img = op.data.numpy()  # Tensor to back in numpy\n",
        "avg_output_img = avg_output_img.reshape((-1, avg_output_img.shape[-1]))\n",
        "print('Avg Pooling:\\n',avg_output_img)\n",
        "print()\n",
        "\n",
        "output.append(avg_output_img)\n",
        "titles.append('Avg Pool output')\n",
        "\n",
        "plot_images(output, titles, tick_params=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fN_Tr_J-3dW"
      },
      "source": [
        "### Convolution on RGB image (Convolution over volume)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV6l677dCori"
      },
      "source": [
        "<img src='https://i.stack.imgur.com/0B1Dr.png' height=220px>\n",
        "\n",
        "\n",
        "Image Reference: [http://datahacker.rs/convolution-rgb-image/](http://datahacker.rs/convolution-rgb-image/)\n",
        "\n",
        "Now, we will perform the convolution and max pooling operation on a RGB image with the edge filters same as above. The only change we make here is the number of input channels in the convolution layer and the filter volume."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqwOHVhJh5iq"
      },
      "source": [
        "# Get sample RGB image\n",
        "!curl -L -o 'image_rgb.jpg' 'https://drive.google.com/uc?export=download&id=1X_1ZWMmVcT-NVeHCcUok3uqQzw4VG3cc'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_gasaswiq2m"
      },
      "source": [
        "image = cv2.imread('image_rgb.jpg')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image = torch.from_numpy(image)\n",
        "\n",
        "# Pytorch requires input to convolution in (N,C,H,W), where N = batch size and C=#channels in input\n",
        "input = image.view((1,3,image.shape[0], image.shape[1])) # Note the no. of channels have changed to 3\n",
        "\n",
        "# --------------KERNEL-------------\n",
        "# Create a nxn kernel\n",
        "kernel_e = generate_filter(3)\n",
        "\n",
        "# Stack 3 filters together (1 filter for each channel of image)\n",
        "kernel = np.dstack((kernel_e, kernel_e, kernel_e))\n",
        "\n",
        "# Create a tensor from the numpy array\n",
        "kernel = torch.from_numpy(kernel.astype(np.float32))\n",
        "\n",
        "# Pytorch requires kernel of shape (N,C,H,W), where N = batch size and C=#channels in input\n",
        "kernel = kernel.view((1,3,kernel.shape[0], kernel.shape[1]))\n",
        "\n",
        "# ---------CONVOLUTION LAYER--------\n",
        "# 1 input image channel, 1 output channels, nxn square convolution with padding on all 4 sides\n",
        "conv = Conv2d(in_channels=3, out_channels=1, kernel_size=3, padding=1, stride=1) # For RGB\n",
        "\n",
        "# Set the kernel weights in the convolution layer\n",
        "conv.weight = torch.nn.Parameter(kernel)\n",
        "\n",
        "# ---------APPLY CONVOLUTION--------\n",
        "output = conv(input / 255.)  # Getting input from 0 to 1\n",
        "output_img = output.data.numpy()  # Tensor to back in numpy\n",
        "output_img = output_img.reshape((-1, output_img.shape[-1])) # Reshape to 2D image\n",
        "\n",
        "\n",
        "# ---------APPLY MAXPOOL-------------\n",
        "pool_layer = MaxPool2d(kernel_size=3, stride=3)\n",
        "op = pool_layer(output)\n",
        "max_output_img = op.data.numpy()  # Tensor to back in numpy\n",
        "max_output_img = max_output_img.reshape((-1, max_output_img.shape[-1]))\n",
        "\n",
        "\n",
        "# Plot output\n",
        "images = []\n",
        "titles = []\n",
        "\n",
        "images.append(image)\n",
        "titles.append('Original Image')\n",
        "images.append(output_img)\n",
        "titles.append('Convolution Output')\n",
        "images.append(max_output_img)\n",
        "titles.append('Max Pooled output')\n",
        "plot_images(images, titles)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYrCQuD_A9W4"
      },
      "source": [
        "Notice the number of input and output channels in the convolution layer and the kernel shape. We are using one kernel for each channel of image, so we stack 3 kernels together. Also, the output channel is just 1, thus, we obtain a grayscale output. Note that we are summing up the 27 values obtained multiplying the image patch with filter (3x3x3), so the number of channels get reduced to 1 in the output. Further, we max pool the convolution output to get a pattern as displayed in the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGnrshREZAcU"
      },
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gImvyMzxcx4e"
      },
      "source": [
        "Q 1: Given a 1-D array [5, 6, 8, 1, 6, 9, 1, 2] and filter [-1, 1], find the convolved output (assume no padding and stride 1).\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8e273-Lawu2"
      },
      "source": [
        "Q 2: Given a 3 x 3 filter with all ones, can you guess what this filter will do when convolved with any image?\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4HVEiJHbqV6"
      },
      "source": [
        "Q 3: The image size is (500, 500) and filter size is 5. The filter is convolved on the image with a stride of 2 and padding 3. What is the obtained output shape?\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oooeJwLhdNWO"
      },
      "source": [
        "Q 4: Given an image \\begin{bmatrix}\n",
        "1 & 2 & 1 & 3 \\\\\n",
        "2 & 3 & 1 & 1 \\\\\n",
        "0 & 2 & 3 & 2 \\\\\n",
        "1 & 1 & 2 & 3\n",
        "\\end{bmatrix} and a filter \\begin{bmatrix}\n",
        "-1 & 2 & 1 \\\\\n",
        "-1 & 0 & 1 \\\\\n",
        "-1 & 2 & 1\n",
        "\\end{bmatrix}\n",
        "Find the convolution output with padding = 1 and stride = 2. Also, calculate the max pooled output with stride = 1 and kernel size = 2.\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfwacAnL_R-q"
      },
      "source": [
        "Q 5: For an RGB image, what is the total number of parameters in the convolution filter of size K?\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBPfDf_FgaeG"
      },
      "source": [
        "### Bonus Question\n",
        "\n",
        "When the lotus image (grayscale) is convolved with the 3x3 edge filter with stride 1 and padding 1 and then max pooled with stride 2 and kernel size 2 to obtain a final output map, what its final output shape? Can you perform the same operations on a RGB image?\n",
        "\n",
        "Answer: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SQpJGaNDckr"
      },
      "source": [
        "## References and Additional Resources\n",
        "\n",
        "\n",
        "*   [Padding and Stride in CNNs](https://machinelearningmastery.com/padding-and-stride-for-convolutional-neural-networks/)\n",
        "*   [Convolution, Padding, Stride, and Pooling in CNN](https://medium.com/analytics-vidhya/convolution-padding-stride-and-pooling-in-cnn-13dc1f3ada26)\n",
        "*   [A Gentle Introduction to Pooling layers in CNNs](https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/)\n",
        "*   [Pooling vs Stride for Downsampling](https://stats.stackexchange.com/questions/387482/pooling-vs-stride-for-downsampling)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pte1SjSyh6fZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2_Multiclass_classification_with_MLP(new).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_7x3NrlFGo78"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fathimath-Rifna-VK/fmml2021/blob/main/Module_8_Lab2_Multiclass_classification_with_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jihotVsFwKh"
      },
      "source": [
        "# Lab 2\n",
        "\n",
        "## Using MLP for multiclass classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP_76wepF6lj"
      },
      "source": [
        "In this notebook we will try to use an MLP for multiclass classification on the iris dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tWls1xEs4IC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzTYvf9atkU6"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0JZiPaNtjWl"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris['data']\n",
        "y = iris['target']\n",
        "names = iris['target_names']\n",
        "feature_names = iris['feature_names']\n",
        "\n",
        "# Scale data to have mean 0 and variance 1\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data set into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6j7J1YWtrLm"
      },
      "source": [
        "# Visualising dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD1UuMr_txc1"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "for target, target_name in enumerate(names):\n",
        "    X_plot = X[y == target]\n",
        "    ax1.plot(X_plot[:, 0], X_plot[:, 1], \n",
        "             linestyle='none', \n",
        "             marker='o', \n",
        "             label=target_name)\n",
        "ax1.set_xlabel(feature_names[0])\n",
        "ax1.set_ylabel(feature_names[1])\n",
        "ax1.axis('equal')\n",
        "ax1.legend();\n",
        "\n",
        "for target, target_name in enumerate(names):\n",
        "    X_plot = X[y == target]\n",
        "    ax2.plot(X_plot[:, 2], X_plot[:, 3], \n",
        "             linestyle='none', \n",
        "             marker='o', \n",
        "             label=target_name)\n",
        "ax2.set_xlabel(feature_names[2])\n",
        "ax2.set_ylabel(feature_names[3])\n",
        "ax2.axis('equal')\n",
        "ax2.legend();\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7x3NrlFGo78"
      },
      "source": [
        "# Observing the dataset\n",
        "\n",
        "Thus, we can observe the dataset and see that there are 3 classes, setosa, versicolor, and virginica.\n",
        "\n",
        "There are 4 features, sepal width, sepal length, petal width, petal length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZROKwQi0t7T5"
      },
      "source": [
        "# MLP for multiclass classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfnKnpVitz3s"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL7l9Mk_uFxG"
      },
      "source": [
        "# Defining the model architecture\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, 50)\n",
        "        self.layer2 = nn.Linear(50, 50)\n",
        "        self.layer3 = nn.Linear(50, 3)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        x = F.softmax(self.layer3(x), dim=1)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5HSl1N4uI2f"
      },
      "source": [
        "# Instantiating the model, using Adam optimiser, and Cross Entropy Loss, which is quite commonlu used for classification tasks.\n",
        "model     = Model(X_train.shape[1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn   = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3mTXyDduQaY"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcLoeG9XuML9"
      },
      "source": [
        "# Train for 100 epochs\n",
        "EPOCHS  = 100\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "X_test= torch.from_numpy(X_test).float()\n",
        "y_test = torch.from_numpy(y_test)\n",
        "y_train = torch.from_numpy(y_train)\n",
        "\n",
        "\n",
        "loss_list     = np.zeros((EPOCHS,))\n",
        "accuracy_list = np.zeros((EPOCHS,))\n",
        "\n",
        "for epoch in tqdm.trange(EPOCHS):\n",
        "    y_pred = model(X_train)\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "    loss_list[epoch] = loss.item()\n",
        "    \n",
        "    # Zero gradients\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        y_pred = model(X_test)\n",
        "        correct = (torch.argmax(y_pred, dim=1) == y_test).type(torch.FloatTensor)\n",
        "        accuracy_list[epoch] = correct.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQdMVtTouqnl"
      },
      "source": [
        "# Plot training progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTNRq4mDutrQ"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(2, figsize=(12, 6), sharex=True)\n",
        "\n",
        "ax1.plot(accuracy_list)\n",
        "ax1.set_ylabel(\"validation accuracy\")\n",
        "ax2.plot(loss_list)\n",
        "ax2.set_ylabel(\"validation loss\")\n",
        "ax2.set_xlabel(\"epochs\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mZO8zVx2DOz"
      },
      "source": [
        "# Experiment with the neural network architecture\n",
        "\n",
        "\n",
        "1.   Try changing the number of hidden layers.\n",
        "2.   Try changing the number of neurons in the hidden layer.\n",
        "3.   Try using a different activation function.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Can you observe any changes?"
      ]
    }
  ]
}
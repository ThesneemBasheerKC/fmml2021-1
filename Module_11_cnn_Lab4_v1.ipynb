{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_lab4-v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fathimath-Rifna-VK/fmml2021/blob/main/Module_11_cnn_Lab4_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQqIVNVYnA90"
      },
      "source": [
        "# Convolutional Neural Networks - Lab 4\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        " <td>\n",
        " <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1uhIW7GMmw8aRFf2ORSFQ65NYl9sxR4WB?usp=sharing\"><img height=\"32px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" />Run in Google Colab</a>\n",
        " </td>\n",
        " <td>\n",
        " <a target=\"_blank\" href=\"https://github.com/Foundations-in-Modern-Machine-Learning/course-contents/blob/main/CNN/cnn_lab4.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        " </td>\n",
        "</table>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "---\n",
        "Module Coordinator: Ekta Gavas\n",
        "\n",
        "Email: ekta.gavas@research.iiit.ac.in\n",
        "\n",
        "## Description\n",
        "---\n",
        "In this lab exercise, we will perform image classification using pretrained CNN models (transfer learning). We will understand two approaches, Fine-tuning and Feature extraction using ResNet architecture to train a model to perform traffic sign classification.\n",
        "\n",
        "## Starter Code\n",
        "---\n",
        "To make your task easier, we provide you the starter code to perform the lab exercises. It is expected that you should try to understand what the code does and analyze the output. We will be using Pytorch framework for the implementation of this lab. The training hyperparameters that are used in the code may not be the best to minimize training time according to lab scope. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7KBF9XrGaSy"
      },
      "source": [
        "## German Traffic Sign classification\n",
        "When a task involves training a CNN on a dataset of images, our first instinct would be to train the network from scratch. However, in practice, CNN has a huge number of parameters, often in the range of millions. Training a CNN on a small dataset greatly affects the network's ability to generalize, often resulting in overfitting.\n",
        "Therefore, in practice, one would fine-tune existing networks that are trained on a large dataset like the ImageNet (1.2M labeled images) by continue training it (i.e. running back-propagation) on the smaller dataset we have. Provided that our dataset is not drastically different in context to the original dataset (e.g. ImageNet), the pre-trained model will already have learned features that are relevant to our own classification problem.  Here, we will understand the Fine-tuning and Feature extraction approach to transfer learning. In the first one, we will take a pretrained ResNet model and replace the classifier to train it on our dataset. In the second approach, we will freeze the weights of the entire network except the classifier and train it on our data. We will thus, analyse the model performance in both cases. The German Traffic Sign Recognition Benchmark (GTSRB) dataset contains 43 classes of traffic signs, with varying light conditions and rich backgrounds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWJa9NQvSdr8"
      },
      "source": [
        "# Import packages\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHCZ__V1uK5R"
      },
      "source": [
        "# Device configuration (whether to run on GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4748CHsYoI2"
      },
      "source": [
        "# Set seeds for reproducibility\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up9pTZ_fuROx"
      },
      "source": [
        "### Load German Traffic Sign dataset\n",
        "To get an idea of using our own datasets with Pytorch, this time, we will not use Pytorch's builtin datasets. The dataset we will use has more than 50K samples. To make the scenario more realistic, the number of samples in each class is limited to 200 only. And we have also reduced the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKAIN6PDub_6"
      },
      "source": [
        "# Download traffic sign dataset\n",
        "!fileid=\"1V7dt70fz_AKRJlttyjnrtFpuJDLXr15x\" && filename=\"german_traffic_signs_dataset.zip\" && curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=${fileid}\" > /dev/null && curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=${fileid}\" -o ${filename}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d13S9bwuiQy"
      },
      "source": [
        "# Unzip\n",
        "!unzip -q german_traffic_signs_dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HQXR2nRP3HJ"
      },
      "source": [
        "The dataset is stored in a folder structure where samples are separated in classwise folders. We can load the entire dataset using Pytorch's ['ImageFolder'](https://pytorch.org/vision/stable/datasets.html#ImageFolder) class. Then, we can see it like any built-in dataset. As the images are of varying shape, we will resize them to fixed dimensions (224,224) and normalize them in range [0,1]. We will here use data augmentation techniques like Gaussian blur and affine transformation to augment the data. This will increase variations in our data and help our model to generalize well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_183iPGunN4"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.GaussianBlur(3),\n",
        "            transforms.RandomAffine(0, translate=(0.3,0.3), shear=5),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = ImageFolder('german_traffic_signs_dataset/Train', transform=transform)\n",
        "testset = ImageFolder('german_traffic_signs_dataset/Test', transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1yRmcSCu4Yu"
      },
      "source": [
        "#### Train, validation and test dataloaders\n",
        "We will split the trainset further to create train-validation split. We will only train on train data and evaluate the model on validation data at each step. The validation metrics helps us to understand whether model is overfitting the data or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GomEiTYu1rI"
      },
      "source": [
        "# Shuffle and split train set into 80% training and 20% validation set\n",
        "val_split = 0.2\n",
        "indices = np.arange(len(trainset))\n",
        "np.random.shuffle(indices)\n",
        "partition = int((1-val_split)*len(trainset))\n",
        "\n",
        "#SubsetRandomSampler will only sample examples from the given subset of data\n",
        "train_loader = DataLoader(trainset, shuffle=False, sampler=SubsetRandomSampler(indices[:partition]), batch_size=64, num_workers=2)\n",
        "val_loader = DataLoader(trainset, shuffle=False, sampler=SubsetRandomSampler(indices[partition:]), batch_size=64, num_workers=2)\n",
        "\n",
        "dataloaders = {'train': train_loader, 'val': val_loader}\n",
        "dataset_sizes = {'train': partition, 'val': len(train_loader.dataset) - partition}\n",
        "\n",
        "test_loader = DataLoader(testset, shuffle=False, batch_size=64, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxDtEgIZvI6r"
      },
      "source": [
        "# Print dataset information\n",
        "print('Number of training images: ', dataset_sizes['train'])\n",
        "print('Number of validation images: ', dataset_sizes['val'])\n",
        "print('Number of test images: ', len(test_loader.dataset))\n",
        "print('Number of classes: ', len(trainset.classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cno25cLvNV-"
      },
      "source": [
        "# Helper function to show an image\n",
        "def plot_image(img):\n",
        "    img = img / 2 + 0.5                         # unnormalize the image\n",
        "    npimg = img.numpy()                         # torch to numpy\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # as torch image is (C, H, W)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Get some random training images from dataloader\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# Plot images\n",
        "plot_image(torchvision.utils.make_grid(images[:20], nrow=5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8xz7oSyvUCu"
      },
      "source": [
        "Helper functions for training/testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJKu5vTyaF-C"
      },
      "source": [
        "def train_model(model, criterion, optimizer, dataloaders, num_epochs=10):\n",
        "    since = time.time()\n",
        "\n",
        "    # best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    val_losses = []\n",
        "    val_acc = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward\n",
        "                # Enable grads if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Running loss and correct predictions\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            # Save loss and acc values\n",
        "            if phase == 'train':\n",
        "              train_losses.append(epoch_loss)\n",
        "              train_acc.append(epoch_acc)\n",
        "            else:\n",
        "              val_losses.append(epoch_loss)\n",
        "              val_acc.append(epoch_acc)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc*100))\n",
        "\n",
        "            # Save the best validation accuracy\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc*100))\n",
        "\n",
        "    return train_losses, val_losses, train_acc, val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZWTjtDwb8L_"
      },
      "source": [
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    test_acc = 0\n",
        "    correct = 0\n",
        "    for i, (images, labels) in enumerate(test_loader):\n",
        "      with torch.no_grad():\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        output = model(images)\n",
        "        _, preds = torch.max(output, dim=1)\n",
        "        correct += (preds == labels).sum()\n",
        "\n",
        "    test_acc = correct / len(test_loader.dataset)\n",
        "    print('Test Accuracy: {:.4f}'.format(test_acc*100))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QExzv8covZIR"
      },
      "source": [
        "### 1. Finetuning\n",
        "Here, we will load a pretrained model ResNet18 available in Pytorch and reset final fully connected layer. The model is trained on ImageNet dataset which is a large dataset containing 1000 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hG2XitCvX4B"
      },
      "source": [
        "# Load pretrained model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# Reset classifier to 43 output units (number of classes in our dataset)\n",
        "model.fc = nn.Linear(model.fc.in_features, 43)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC999ilMTx52"
      },
      "source": [
        "#### Define loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2Sey-3y3UKJ"
      },
      "source": [
        "# Cross Entropy loss for multi-class classification\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7YjI7Y0T1f2"
      },
      "source": [
        "#### Define optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNjCtOyBT419"
      },
      "source": [
        "# SGD optimizer with momentum\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgpDdgB0wGAU"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaC-PUeNv8xJ"
      },
      "source": [
        "# Accuracy on test data before training\n",
        "test_model(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p5M87hTv9E7"
      },
      "source": [
        "history = train_model(model, criterion, optimizer, dataloaders, num_epochs=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6ltVbRI4dr6"
      },
      "source": [
        "Plot training plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPJHC1_tIFAr"
      },
      "source": [
        "fig = plt.figure(figsize=(10,4))\n",
        "ax = fig.add_subplot(1,2, 1)\n",
        "ax.plot(np.arange(1,len(history[0])+1),history[0])\n",
        "ax.plot(np.arange(1,len(history[1])+1),history[1])\n",
        "plt.xlabel('Loss')\n",
        "plt.ylabel('Epochs')\n",
        "plt.legend(['Train Loss', 'Val Loss'])\n",
        "\n",
        "\n",
        "ax = fig.add_subplot(1,2, 2)\n",
        "ax.plot(np.arange(1,len(history[2])+1),history[2])\n",
        "ax.plot(np.arange(1,len(history[3])+1),history[3])\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Epochs')\n",
        "plt.legend(['Train Acc', 'Val Acc'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhVyadHIU9FY"
      },
      "source": [
        "#### Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_4-zXsxVB3i"
      },
      "source": [
        "# Accuracy on test data after training\n",
        "test_model(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Id93lgE1kdd"
      },
      "source": [
        "### 2. Feature Extraction\n",
        "Here, in the second approach, we will create a new instance of network and freeze entire network parameters except the final layer. We need to set ***requires_grad == False*** to freeze the parameters so that the gradients are not computed in backward()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfrJQuaVv9Hs"
      },
      "source": [
        "# Load pretrained model\n",
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze all parameters\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of new classifier have requires_grad=True by default\n",
        "# so grads will be computed for classifier only\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 43)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cgk1ahfE17Rp"
      },
      "source": [
        "# Evaluate model on test data before training\n",
        "print('Before training')\n",
        "test_model(model_conv, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNC6rLI32G65"
      },
      "source": [
        "####Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hLRYy2rv9OS"
      },
      "source": [
        "history = train_model(model_conv, criterion, optimizer_conv, dataloaders, num_epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuSbIAfI2nnc"
      },
      "source": [
        "fig = plt.figure(figsize=(10,4))\n",
        "ax = fig.add_subplot(1,2, 1)\n",
        "ax.plot(np.arange(1,len(history[0])+1),history[0])\n",
        "ax.plot(np.arange(1,len(history[1])+1),history[1])\n",
        "plt.xlabel('Loss')\n",
        "plt.ylabel('Epochs')\n",
        "plt.legend(['Train Loss', 'Val Loss'])\n",
        "\n",
        "\n",
        "ax = fig.add_subplot(1,2, 2)\n",
        "ax.plot(np.arange(1,len(history[2])+1),history[2])\n",
        "ax.plot(np.arange(1,len(history[3])+1),history[3])\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Epochs')\n",
        "plt.legend(['Train Acc', 'Val Acc'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAvn3h1g2sR-"
      },
      "source": [
        "#### Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ylntBgw2sR_"
      },
      "source": [
        "# Accuracy on test data after training\n",
        "test_model(model_conv, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSbdv4UPVfdp"
      },
      "source": [
        "As you can see, the test accuracy for feature extraction approach is not good compared to the first approach, although we are using pretrained models in both cases. Also, note that the training time was reduced to about half this time. This is obvious as we are not computing all the gradients this time. Experiment with the hyper-parameters like learning rate, epochs, and also optimizers till model convergence.Did you observe any improvement in the performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45jHKIHt6iM-"
      },
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mjppKyXWKaR"
      },
      "source": [
        "Q 1: Why do you think the network did not achieve good test accuracy in the feature extraction approach?\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-FfAbYBW_qA"
      },
      "source": [
        "Q 2: Can you think of a scenario where the feature extraction approach would be preferred compared to fine tuning approach?\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ2TU3_uawLc"
      },
      "source": [
        "Q 3: Replace the ResNet18 architecture with some other pretrained model in pytorch and try to find the optimal parameters. Report the architecture and the final model performance.\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOHxNtgt3qM2"
      },
      "source": [
        "Q 4: Which other data augmentations can we used to augment the data?\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9laBnu8Y4S4_"
      },
      "source": [
        "Q 5: If our dataset is drastically is different in context from the dataset which the pre-trained model is trained on, would the transfer learning approaches be of much help?\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsalBk66WZIn"
      },
      "source": [
        "## References and Additional Resources:\n",
        "\n",
        "*   [Transfer Learning Pytorch tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#id1)\n",
        "*   [Transfer Learning with Convolutional Neural Networks in PyTorch](https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce)\n",
        "*    [Torchvision models](https://pytorch.org/vision/stable/models.html)\n",
        "*    [A Comprehensive Hands-on Guide to Transfer Learning with Real-World Applications in Deep Learning](https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmp0BvGYjwhZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FMML:M10:Lab5",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fathimath-Rifna-VK/fmml2021/blob/main/Module_10_FMML_M10_Lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP6fl0GKybI9"
      },
      "source": [
        "# Introduction to `pytorch-lightning`\n",
        "\n",
        "Machine learning is basically updating a float vector smartly. We don't actually need pytorch for that. There is a lot of ML stuff that runs on plain `numpy`. We use `pytorch` because it makes our lives easier.\n",
        "\n",
        "As `pytorch` is a framework for machine learning (basically a library for managing tensors), `pytorch-lightning` is a wrapper for `pytorch` itself!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfUeoSfW08UX"
      },
      "source": [
        "PyTorch Lightning is just organized PyTorch!\n",
        "\n",
        "Lightning structures PyTorch code with these principles:\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/philosophies.jpg\" max-height=\"250px\">\n",
        "</div>\n",
        "\n",
        "## Advantages over unstructured PyTorch\n",
        "\n",
        "* Models become hardware agnostic\n",
        "* Code is clear to read because engineering code is abstracted away\n",
        "* Easier to reproduce\n",
        "* Make fewer mistakes because lightning handles the tricky engineering\n",
        "* Keeps all the flexibility (LightningModules are still PyTorch modules), but removes a ton of boilerplate\n",
        "* Lightning has dozens of integrations with popular machine learning tools."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c5oU9EVo-S6"
      },
      "source": [
        "!pip install pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax380t4GpVnH"
      },
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import pytorch_lightning as pl\n",
        "from skimage import io\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTzzqZPSnjDu"
      },
      "source": [
        "We'll be using the same example as the last lab, but now with `pytorch-lightning`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu7IamLHyRpI"
      },
      "source": [
        "# download the example dataset\n",
        "!rm -r data cifar10.zip\n",
        "!mkdir data\n",
        "# slightly modified version of https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "!wget https://web.iiit.ac.in/~yoogottam.khandelwal/cifar10.zip\n",
        "!unzip cifar10.zip -d data | tail"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye7Pn2YSoZc3"
      },
      "source": [
        "class CIFAR10Dataset(Dataset):\n",
        "    def __init__(self, root_dir=\"./data\", transforms=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir   (string)  : Directory with all the images and the csv file\n",
        "            transforms (Callable): image goes through these transforms\n",
        "        \"\"\"\n",
        "        # use pandas to read the csv\n",
        "        # we are only using 1/10th of the full data because CIFAR10 is HUGE\n",
        "        # otherwise, we wouldn't be able to train this\n",
        "        self.data = pd.read_csv(f\"{root_dir}/data.csv\").sample(frac=0.1, random_state=42)\n",
        "        # this is where the images are stored\n",
        "        self.root_dir = root_dir\n",
        "\n",
        "        # label encoder\n",
        "        label_encoder = LabelEncoder()\n",
        "        self.data[\"label_numeric\"] = label_encoder.fit_transform(self.data[\"label\"])\n",
        "\n",
        "        # transformations to the dataset\n",
        "        # we'll come to this soon\n",
        "        if transforms is None:\n",
        "            # an identity function, returns it's argument\n",
        "            transforms = lambda x: x\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        This should return the number of items in the dataset\n",
        "        \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        This should return the item at index `idx` from the dataset\n",
        "        \"\"\"\n",
        "        data = self.data.iloc[idx]\n",
        "        img_name = os.path.join(self.root_dir, data[\"image_path\"])\n",
        "        # read the image\n",
        "        image = io.imread(img_name)\n",
        "        label = data[\"label\"]\n",
        "        label_numeric = data[\"label_numeric\"]\n",
        "\n",
        "        # send the image through the provided transformations\n",
        "        image = self.transforms(image)\n",
        "        return image, label_numeric, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEXpw4iEschM"
      },
      "source": [
        "Now, we'll use a `LightningModule` to define our model.\n",
        "\n",
        "A `LightningModule` is basically a torch `nn.Module` but using this allows us to structure our code in a better way.\n",
        "\n",
        "No change in the model code at all (except now we are inheriting from a different class)\n",
        "\n",
        "On top of that, we configure the optimizers here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R40Eyj1Ys2hB"
      },
      "source": [
        "class CIFAR10Module(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(in_features=3072, out_features=1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=1024, out_features=512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=512, out_features=128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=128, out_features=32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=32, out_features=10),\n",
        "        )\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters(), lr=1e-3)\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # pytorch-lightning will take care of\n",
        "        # moving stuff to the correct device\n",
        "        images, y, _ = batch\n",
        "        x = images.view(images.size(0), -1)\n",
        "        out = model(x)\n",
        "        loss = self.loss(out, y)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W35pd_9euf24"
      },
      "source": [
        "cifar10_ds = CIFAR10Dataset(transforms=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # the order is flipped because RandomHorizontalFlip expects a tensor\n",
        "    # almost always we'll convert the data to a tensor first\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "]))\n",
        "\n",
        "train_dl = DataLoader(cifar10_ds, batch_size=256, shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC7AU6nBttUl"
      },
      "source": [
        "# Training\n",
        "\n",
        "Now that we have a `LightningModule`, we don't need to write the training code ourselves. `pytorch-lightning` provides us a `Trainer`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z46V-JJcxZGy"
      },
      "source": [
        "trainer = pl.Trainer(max_epochs=30)\n",
        "model = CIFAR10Module()\n",
        "\n",
        "trainer.fit(model, train_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqHRlfwe0Pqp"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRd6ZhwA01QZ"
      },
      "source": [
        "# References\n",
        " - https://github.com/PyTorchLightning/pytorch-lightning\n",
        " - https://towardsdatascience.com/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09\n",
        " - https://pytorch.org/vision/stable/transforms.html"
      ]
    }
  ]
}
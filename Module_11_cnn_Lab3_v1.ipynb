{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cnn-lab3_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fathimath-Rifna-VK/fmml2021/blob/main/Module_11_cnn_Lab3_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQqIVNVYnA90"
      },
      "source": [
        "# Convolutional Neural Networks - Lab 3\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        " <td>\n",
        " <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1OOG0_aCrwPIIb8-M0al0zcHTX05YMOs0?usp=sharing\"><img height=\"32px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" />Run in Google Colab</a>\n",
        " </td>\n",
        " <td>\n",
        " <a target=\"_blank\" href=\"https://github.com/Foundations-in-Modern-Machine-Learning/course-contents/blob/main/CNN/cnn_lab3.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        " </td>\n",
        "</table>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "---\n",
        "Module Coordinator: Ekta Gavas\n",
        "\n",
        "Email: ekta.gavas@research.iiit.ac.in\n",
        "\n",
        "## Description\n",
        "---\n",
        "In this lab exercise, we will study image classification problem using CNNs with RGB images. We will implement a basic CNN model for classifying CIFAR10 images and train it end-to-end and evaluate our model on test data. We will then visualize the kernels and intermediate feature maps i.e the output of intermediate layers.\n",
        "\n",
        "## Starter Code\n",
        "---\n",
        "To make your task easier, we provide you the starter code to perform the lab exercises. It is expected that you should try to understand what the code does and analyze the output. We will be using Pytorch framework for the implementation of this lab. The training hyperparameters that are used in the code may not be the best to minimize training time according to lab scope. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7KBF9XrGaSy"
      },
      "source": [
        "## CIFAR10 Image classification\n",
        "\n",
        "**We will do the following steps in order:**\n",
        "1.   Load and normalize CIFAR10 training and test datasets using torchvision and visualize few samples\n",
        "2.   Define the CNN model\n",
        "3.   Define a loss function and optimizer\n",
        "4.   Train the network on the training data\n",
        "5.   Evaluate the network on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFz2LDnSZ4fz"
      },
      "source": [
        "# Import packages\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpnQlJ62Ohz8"
      },
      "source": [
        "# Device configuration (whether to run on GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0seI6zqZBwQ"
      },
      "source": [
        "# Set seeds for reproducibility\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng9B8F-DG9Xj"
      },
      "source": [
        "#### Load CIFAR10 data\n",
        "We will use the [CIFAR10 dataset](https://pytorch.org/vision/stable/datasets.html#cifar) from torchvision Pytorch and setup the train and test dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPIoFf3t2-Ox"
      },
      "source": [
        "# Images returned from torchvision dataset classes is in range [0,1]\n",
        "# We transform them to tensors and normalize them to range [-1,1] using 'Normalize' transform\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "# Classes in CIFAR10\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKFFF26XO0EO"
      },
      "source": [
        "print('Training data shape : ', trainset.data.shape, len(trainset.targets))\n",
        "print('Testing data shape : ', testset.data.shape, len(testset.targets))\n",
        "\n",
        "# Find the unique numbers from the train labels\n",
        "nClasses = len(classes)\n",
        "print('Total number of outputs : ', nClasses)\n",
        "print('Output classes : ', classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma926DN83N2e"
      },
      "source": [
        "# Helper function to show an image\n",
        "def plot_image(img):\n",
        "    img = img / 2 + 0.5                         # unnormalize the image\n",
        "    npimg = img.numpy()                         # torch to numpy\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))  # as torch image is (C, H, W)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images from dataloader\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# Plot images\n",
        "plot_image(torchvision.utils.make_grid(images[:4]))\n",
        "\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t94F0wxMefKz"
      },
      "source": [
        "Helper functions for training/testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDXNReyi8n5o"
      },
      "source": [
        "def train(num_epochs, model, train_loader, loss_func, optimizer):\n",
        "\n",
        "  # Training mode\n",
        "  model.train()\n",
        "\n",
        "  train_losses = []\n",
        "  train_acc = []\n",
        "\n",
        "  # Train the model\n",
        "  for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    running_acc = 0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "      \n",
        "      # clear gradients for this training step   \n",
        "      optimizer.zero_grad()           \n",
        "\n",
        "      # Put data on devices\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Forward pass\n",
        "      output = model(images)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = loss_func(output, labels)\n",
        "\n",
        "      # Backpropagation, compute gradients \n",
        "      loss.backward()\n",
        "\n",
        "      # Apply gradients             \n",
        "      optimizer.step()                \n",
        "      \n",
        "      # Running loss\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      # indices of max probabilities\n",
        "      _, preds = torch.max(output, dim=1)\n",
        "\n",
        "      # Calculate number of correct predictions\n",
        "      correct = (preds.float() == labels).sum()\n",
        "      running_acc += correct\n",
        "\n",
        "      # Average loss and acc values \n",
        "      epoch_loss = running_loss / len(train_loader.dataset)\n",
        "      epoch_acc = running_acc / len(train_loader.dataset)\n",
        "\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_acc.append(epoch_acc)\n",
        "    print ('Epoch {}/{}, Loss: {:.4f}, Accuracy: {:.4f}'.format(epoch + 1, num_epochs, epoch_loss, epoch_acc*100))\n",
        "\n",
        "  return train_losses, train_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE2L3trR232_"
      },
      "source": [
        "def test_model(model, testloader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  # Deactivate autograd engine (don't compute grads since we're not training)\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "          # Calculate outputs by running images through the network\n",
        "          outputs = model(images)\n",
        "          # The class with the highest value is what we choose as prediction\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network: %d %%' % (\n",
        "      100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7wmq8NkTntL"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npM6CaBL3RE5"
      },
      "source": [
        "# CNN with 2 CONV layers and 3 FC layers\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
        "        self.fc1 = nn.Linear(32 * 5 * 5, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        # output layer 10 classes\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        # flatten all dimensions except batch\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZp8pdjkxTNm"
      },
      "source": [
        "model = Net().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC999ilMTx52"
      },
      "source": [
        "### Define loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2Sey-3y3UKJ"
      },
      "source": [
        "# Cross Entropy loss for multi-class classification\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7YjI7Y0T1f2"
      },
      "source": [
        "### Define optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNjCtOyBT419"
      },
      "source": [
        "# SGD optimizer with momentum\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peJpeJPNUHxj"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1LS-WmcUvc8"
      },
      "source": [
        "# Accuracy on test data before training\n",
        "test_model(model, testloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwM7zbNlUQoY"
      },
      "source": [
        "num_epochs = 15  # iterations\n",
        "train_losses, train_acc = train(num_epochs, model, trainloader, criterion, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6ltVbRI4dr6"
      },
      "source": [
        "Plot training plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPJHC1_tIFAr"
      },
      "source": [
        "fig = plt.figure(figsize=(10,4))\n",
        "ax = fig.add_subplot(1,2, 1)\n",
        "ax.plot(np.arange(1,len(train_losses)+1),train_losses)\n",
        "plt.xlabel('Training loss')\n",
        "plt.ylabel('Epochs')\n",
        "ax.set_title('Loss vs Epochs')\n",
        "ax = fig.add_subplot(1,2, 2)\n",
        "ax.plot(np.arange(1,len(train_acc)+1),train_acc)\n",
        "plt.xlabel('Training accuracy')\n",
        "plt.ylabel('Epochs')\n",
        "ax.set_title('Accuracy vs Epochs')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u11N21yRU526"
      },
      "source": [
        "As you can see the model has not converged. Experiment with the hyper-parameters like learning rate, epochs, and also optimizers. What change did you observe in the performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhVyadHIU9FY"
      },
      "source": [
        "### Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_4-zXsxVB3i"
      },
      "source": [
        "# Accuracy on test data after training\n",
        "test_model(model, testloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-MMRuX9Yb7v"
      },
      "source": [
        "The test accuracy is very less compared to training accuracy. The model doesn't perform equally well on unseen data. Let's see the predictions on few test images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwvGGCUk3ZHu"
      },
      "source": [
        "# print few test images\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "plot_image(torchvision.utils.make_grid(images[:4]))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMD4r8k63ifG"
      },
      "source": [
        "# Get predictions on test images\n",
        "outputs = model(images.to(device))\n",
        "\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFMhffouZtkZ"
      },
      "source": [
        "Let's see the test accuracy for each class in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdcNZiOs3u-C"
      },
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
        "                                                   accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sVfEegnaVbX"
      },
      "source": [
        "## Feature map visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga0Az1zLcPVz"
      },
      "source": [
        "Save the conv layers and their weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En_ZpAdpvVts"
      },
      "source": [
        "model_weights = [] # we will save the conv layer weights in this list\n",
        "conv_layers = [] # we will save the conv layers in this list\n",
        "# get all the model children as list\n",
        "model_children = list(model.children())\n",
        "\n",
        "# counter to keep count of the conv layers\n",
        "counter = 0 \n",
        "# append all the conv layers and their respective weights to the list\n",
        "for i in range(len(model_children)):\n",
        "    if type(model_children[i]) == nn.Conv2d:\n",
        "        counter += 1\n",
        "        model_weights.append(model_children[i].weight)\n",
        "        conv_layers.append(model_children[i])\n",
        "    elif type(model_children[i]) == nn.Sequential:\n",
        "        for j in range(len(model_children[i])):\n",
        "            for child in model_children[i][j].children():\n",
        "                if type(child) == nn.Conv2d:\n",
        "                    counter += 1\n",
        "                    model_weights.append(child.weight)\n",
        "                    conv_layers.append(child)\n",
        "print(f\"Total convolutional layers: {counter}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N34IYC8Fziq1"
      },
      "source": [
        "# take a look at the conv layers and the respective weights\n",
        "for weight, conv in zip(model_weights, conv_layers):\n",
        "    # print(f\"WEIGHT: {weight} \\nSHAPE: {weight.shape}\")\n",
        "    print(f\"CONV: {conv} ====> SHAPE: {weight.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qhgNqhgcTpW"
      },
      "source": [
        "### Visualize the CONV layer filters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCH5GBQpznZw"
      },
      "source": [
        "# Visualize the conv layer filters\n",
        "plt.figure(figsize=(20, 17))\n",
        "for i, filter in enumerate(model_weights[0]):\n",
        "    plt.subplot(8, 8, i+1) # (8, 8)\n",
        "    plt.imshow(filter[0, :, :].data.cpu().numpy(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UPNns-hcbWK"
      },
      "source": [
        "### Visualize filter outputs on an image\n",
        "Get an image from test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV_7rEx3zpuy"
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "img = images.data[1:2]\n",
        "fig = plt.figure(figsize=(3,3))\n",
        "plot_image(img.reshape((3,32,32)))\n",
        "print(classes[labels.data[1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajfFCveAxpf-"
      },
      "source": [
        "Forward pass the image through saved conv layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR6LxW9t0ADw"
      },
      "source": [
        "results = [conv_layers[0](img.to(device))]\n",
        "for i in range(1, len(conv_layers)):\n",
        "    # pass the result from the last layer to the next layer\n",
        "    results.append(conv_layers[i](results[-1]))\n",
        "# make a copy of the `results`\n",
        "outputs = results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkeMeBQdxwpP"
      },
      "source": [
        "Visualize features from each layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDuxp0nq0BEX"
      },
      "source": [
        "for num_layer in range(len(outputs)):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    layer_viz = outputs[num_layer][0, :, :, :]\n",
        "    layer_viz = layer_viz.data\n",
        "    print('Layer output size:', layer_viz.size())\n",
        "    for i, filter in enumerate(layer_viz):\n",
        "        plt.subplot(8, 8, i + 1)\n",
        "        plt.imshow(filter.cpu().numpy(), cmap='gray')\n",
        "        plt.axis(\"off\")\n",
        "    print(f\"Layer {num_layer} feature maps...\")\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-IF3nmaxzQF"
      },
      "source": [
        "As you can observe, the filters in first conv layer (Layer 0) detect low level features whereas second conv layer (Layer 1) detect more complex features. Thus, as you move towards the output layer, the features become more complex."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiLzgWJld831"
      },
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pif9YB0GeCdE"
      },
      "source": [
        "Q 1: Calculate the total number of parameters in the above network (We have a bias parameter for each filter).\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeqhVLsTe7zK"
      },
      "source": [
        "Q 2: What is the size of the feature map obtained for a given input image (n x n) convolved with kernel (k x k), stride (s), and padding (p)?\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIMxdcLTgRmJ"
      },
      "source": [
        "Q 3: Does the size of the feature map always reduce upon applying the filters? Explain why or why not.\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGSiWKWchmox"
      },
      "source": [
        "Q 4: Can we use CNN to perform Dimensionality Reduction? If Yes, then which layer is responsible for dimensionality reduction particularly in CNN? \n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lnKwutLh_Yu"
      },
      "source": [
        "Q 5: Which of the following statements is true when you use 1×1 convolutions in a CNN?\n",
        "\n",
        "A. It can help in dimensionality reduction\n",
        "\n",
        "B. It can be used for feature pooling\n",
        "\n",
        "C. It suffers less overfitting due to small kernel size\n",
        "\n",
        "D. All of the above\n",
        "\n",
        "Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAmVRBaTbRVX"
      },
      "source": [
        "## References and Additional Resources\n",
        "\n",
        "*   [Training a classifier tutorial - Pytorch](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-an-image-classifier)\n",
        "*   [Visualizing Filters and Feature Maps in Convolutional Neural Networks using PyTorch](https://debuggercafe.com/visualizing-filters-and-feature-maps-in-convolutional-neural-networks-using-pytorch/)\n",
        "*   [ConvNetJS CIFAR10 Demo](https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehgCDoNF0hL8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}